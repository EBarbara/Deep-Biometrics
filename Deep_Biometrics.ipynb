{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Biometrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EBarbara/Deep-Biometrics/blob/master/Deep_Biometrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz7KgnAP4iK0"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "from scipy.io.arff import loadarff\n",
        "In this notebook, we improve on our intermediate neural net by applying the theory we've covered since."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAEoRfRv5Aei"
      },
      "source": [
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYDPbxja5AGr",
        "outputId": "7eff546c-2f23-4b86-d4aa-9dde3482bbe5"
      },
      "source": [
        "!pip install arff \n",
        "!pip install scipy==1.7.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arff\n",
            "  Downloading arff-0.9.tar.gz (4.7 kB)\n",
            "Building wheels for collected packages: arff\n",
            "  Building wheel for arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arff: filename=arff-0.9-py3-none-any.whl size=4971 sha256=f0c9f209803ef05e10fa8fed39dd4c5049796e9c1866752020099d2e556bc00b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/81/bd/4ae90e24ba860304e375da219f9205b2586dbee255f3ee70e2\n",
            "Successfully built arff\n",
            "Installing collected packages: arff\n",
            "Successfully installed arff-0.9\n",
            "Collecting scipy==1.7.1\n",
            "  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.5 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy==1.7.1) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "id": "9INJzmJ3ot8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EirVrdUl4otF"
      },
      "source": [
        "Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F9C0oOp4dmn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from glob import glob\n",
        "from scipy.io.arff import loadarff\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    BatchNormalization,\n",
        "    Bidirectional,\n",
        "    Conv1D,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    GRU,\n",
        "    LSTM,\n",
        "    MaxPooling1D,\n",
        "    SimpleRNN,\n",
        ")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLWGZZgy5Qgc"
      },
      "source": [
        "Load and read dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt4_6n-c4lis",
        "outputId": "9de35e98-75dd-4bbc-e962-ecf9ab5b68d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN7LucKt5Tjc",
        "outputId": "e544828d-384a-4b2e-e2c5-8282571e4645"
      },
      "source": [
        "# Get a list of all the csv files\n",
        "arf_files = glob('/content/drive/MyDrive/Deep Learning/wisdm/*.arff')\n",
        "\n",
        "dfs = pd.concat((pd.DataFrame(loadarff(file)[0]) for file in arf_files))\n",
        "# List comprehension that loads of all the files\n",
        "\n",
        "# List comprehension that looks at the shape of all DataFrames\n",
        "print(dfs)\n",
        "print(len(dfs.index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    \"ACTIVITY\"   \"X0\"   \"X1\"   \"X2\"  ...   \"XZCOR\"   \"YZCOR\"  \"RESULTANT\"  \"class\"\n",
            "0         b'A'  0.205  0.130  0.300  ...  0.252518  0.102834     11.44030  b'1603'\n",
            "1         b'A'  0.210  0.135  0.325  ...  0.396639  0.163752     11.20960  b'1603'\n",
            "2         b'A'  0.195  0.185  0.225  ...  0.462766  0.097135     11.53580  b'1603'\n",
            "3         b'A'  0.210  0.155  0.255  ...  0.387476  0.177059     11.58630  b'1603'\n",
            "4         b'A'  0.205  0.185  0.205  ...  0.406013  0.151663     11.89350  b'1603'\n",
            "..         ...    ...    ...    ...  ...       ...       ...          ...      ...\n",
            "322       b'S'  0.035  0.420  0.500  ... -0.187801  0.238269      2.02908  b'1647'\n",
            "323       b'S'  0.065  0.475  0.400  ... -0.296492 -0.157986      1.97007  b'1647'\n",
            "324       b'S'  0.100  0.385  0.385  ... -0.304941 -0.014148      2.38792  b'1647'\n",
            "325       b'S'  0.070  0.450  0.420  ... -0.279471 -0.116086      2.00288  b'1647'\n",
            "326       b'S'  0.080  0.465  0.375  ... -0.264017 -0.017867      2.17372  b'1647'\n",
            "\n",
            "[75099 rows x 93 columns]\n",
            "75099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT0sLL22DOLL"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg0NgmU3DQRC"
      },
      "source": [
        "#(df_train, df_valid) = dfs\n",
        "df_train, df_bolo = train_test_split(dfs, test_size=0.2,stratify=dfs['\"ACTIVITY\"'])\n",
        "df_valid, df_test = train_test_split(df_bolo, test_size=0.5,stratify=df_bolo['\"ACTIVITY\"'])\n",
        "\n",
        "X_train = df_train.drop('\"ACTIVITY\"', axis=1)\n",
        "y_train = df_train['\"ACTIVITY\"']\n",
        "\n",
        "X_valid = df_valid.drop('\"ACTIVITY\"', axis=1)\n",
        "y_valid = df_valid['\"ACTIVITY\"']\n",
        "\n",
        "X_test = df_test.drop('\"ACTIVITY\"', axis=1)\n",
        "y_test = df_test['\"ACTIVITY\"']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h93kbgvqDg7i"
      },
      "source": [
        "Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqGfu_Y1Diji"
      },
      "source": [
        "n_classes = 18\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train=le.transform(y_train)\n",
        "le.fit(y_valid)\n",
        "y_valid=le.transform(y_valid)\n",
        "\n",
        "le.fit(y_test)\n",
        "y_test=le.transform(y_test)\n",
        "\n",
        "le.fit(X_valid['\"class\"'])\n",
        "X_valid['\"class\"'] = le.transform(X_valid['\"class\"'])\n",
        "le.fit(X_train['\"class\"'])\n",
        "X_train['\"class\"'] = le.transform(X_train['\"class\"'])\n",
        "\n",
        "le.fit(X_test['\"class\"'])\n",
        "X_test['\"class\"'] = le.transform(X_test['\"class\"'])\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, n_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUkqz6nvEgqz"
      },
      "source": [
        "# build the scaler model\n",
        "scaler = MinMaxScaler()\n",
        "# fit using the train set\n",
        "\n",
        "# transform the test test\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.fit_transform(X_valid)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "X_train_scaled = X_train_scaled[:,0:92].astype(float)\n",
        "#print(X_train_scaled.shape)\n",
        "X_test_scaled = X_test_scaled[:,0:92].astype(float)\n",
        "X_valid_scaled = X_valid_scaled[:,0:92].astype(float)\n",
        "X_train_scaled = X_train_scaled.reshape(-1,92).astype('float32')\n",
        "X_valid_scaled  = X_valid_scaled.reshape(-1,92).astype('float32')\n",
        "X_test_scaled  = X_test_scaled.reshape(-1,92).astype('float32')\n",
        "\n",
        "X_train_scaled_2d = X_train_scaled.reshape(-1,1,92).astype('float32')\n",
        "X_valid_scaled_2d  = X_valid_scaled.reshape(-1,1,92).astype('float32')\n",
        "X_test_scaled_2d  = X_test_scaled.reshape(-1,1,92).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-WtAq44O8p8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA dos dados de entrada"
      ],
      "metadata": {
        "id": "1JIhX9hbPElb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_best_fit = 30\n",
        "\n",
        "pca = PCA(n_components=pca_best_fit)\n",
        "pca.fit(X_train_scaled)\n",
        "\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "\n",
        "X_train_scaled_pca = pca.transform(X_train_scaled)\n",
        "X_valid_scaled_pca = pca.transform(X_valid_scaled)\n",
        "X_test_scaled_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "X_train_scaled_pca_2d = X_train_scaled_pca.reshape(-1,1,pca_best_fit).astype('float32')\n",
        "X_valid_scaled_pca_2d = X_valid_scaled_pca.reshape(-1,1,pca_best_fit).astype('float32')\n",
        "X_test_scaled_pca_2d = X_test_scaled_pca.reshape(-1,1,pca_best_fit).astype('float32')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FPKEjIF-PIEY",
        "outputId": "327b0416-7d66-42b2-a50d-738070664779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7MC1ct6xPGxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste com rede shallow"
      ],
      "metadata": {
        "id": "R8M5nCTe5BFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(92, activation='tanh', input_shape=(92,)))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK4UcSeJ5EKb",
        "outputId": "f4ea56c0-05b9-4895-e42d-3c17a68ace16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 92)                8556      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 18)                1674      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,230\n",
            "Trainable params: 10,230\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])\n",
        "model.fit(X_train_scaled, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1toXV6XS5al8",
        "outputId": "35b06c03-273c-450b-8ff8-f09e324d565f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 2.6109 - accuracy: 0.1489 - val_loss: 2.4325 - val_accuracy: 0.1997\n",
            "Epoch 2/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.3694 - accuracy: 0.2044 - val_loss: 2.3220 - val_accuracy: 0.2087\n",
            "Epoch 3/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2978 - accuracy: 0.2250 - val_loss: 2.2674 - val_accuracy: 0.2273\n",
            "Epoch 4/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2572 - accuracy: 0.2414 - val_loss: 2.2584 - val_accuracy: 0.2467\n",
            "Epoch 5/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2297 - accuracy: 0.2511 - val_loss: 2.2295 - val_accuracy: 0.2317\n",
            "Epoch 6/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2069 - accuracy: 0.2627 - val_loss: 2.1852 - val_accuracy: 0.2696\n",
            "Epoch 7/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1879 - accuracy: 0.2712 - val_loss: 2.2149 - val_accuracy: 0.2692\n",
            "Epoch 8/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1731 - accuracy: 0.2759 - val_loss: 2.3323 - val_accuracy: 0.2318\n",
            "Epoch 9/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1583 - accuracy: 0.2812 - val_loss: 2.2052 - val_accuracy: 0.2678\n",
            "Epoch 10/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1477 - accuracy: 0.2859 - val_loss: 2.1786 - val_accuracy: 0.2569\n",
            "Epoch 11/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1363 - accuracy: 0.2919 - val_loss: 2.1313 - val_accuracy: 0.2763\n",
            "Epoch 12/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1221 - accuracy: 0.2963 - val_loss: 2.1196 - val_accuracy: 0.2928\n",
            "Epoch 13/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1131 - accuracy: 0.2963 - val_loss: 2.2193 - val_accuracy: 0.2647\n",
            "Epoch 14/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1007 - accuracy: 0.2999 - val_loss: 2.0889 - val_accuracy: 0.2981\n",
            "Epoch 15/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0882 - accuracy: 0.3055 - val_loss: 2.2375 - val_accuracy: 0.2293\n",
            "Epoch 16/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0731 - accuracy: 0.3107 - val_loss: 2.0848 - val_accuracy: 0.3056\n",
            "Epoch 17/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0625 - accuracy: 0.3129 - val_loss: 2.1061 - val_accuracy: 0.2847\n",
            "Epoch 18/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0498 - accuracy: 0.3178 - val_loss: 2.0461 - val_accuracy: 0.3123\n",
            "Epoch 19/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0373 - accuracy: 0.3236 - val_loss: 2.0825 - val_accuracy: 0.2957\n",
            "Epoch 20/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0248 - accuracy: 0.3241 - val_loss: 2.1413 - val_accuracy: 0.2712\n",
            "Epoch 21/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0098 - accuracy: 0.3305 - val_loss: 2.0041 - val_accuracy: 0.3329\n",
            "Epoch 22/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0019 - accuracy: 0.3324 - val_loss: 2.0965 - val_accuracy: 0.2915\n",
            "Epoch 23/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9906 - accuracy: 0.3361 - val_loss: 2.0063 - val_accuracy: 0.3232\n",
            "Epoch 24/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9733 - accuracy: 0.3430 - val_loss: 2.0470 - val_accuracy: 0.3057\n",
            "Epoch 25/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9599 - accuracy: 0.3471 - val_loss: 2.0498 - val_accuracy: 0.2996\n",
            "Epoch 26/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9465 - accuracy: 0.3522 - val_loss: 1.9385 - val_accuracy: 0.3465\n",
            "Epoch 27/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9358 - accuracy: 0.3545 - val_loss: 1.9795 - val_accuracy: 0.3249\n",
            "Epoch 28/200\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 1.9238 - accuracy: 0.3589 - val_loss: 1.9706 - val_accuracy: 0.3264\n",
            "Epoch 29/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9075 - accuracy: 0.3656 - val_loss: 1.9635 - val_accuracy: 0.3426\n",
            "Epoch 30/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8942 - accuracy: 0.3681 - val_loss: 1.9116 - val_accuracy: 0.3602\n",
            "Epoch 31/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8834 - accuracy: 0.3736 - val_loss: 1.9298 - val_accuracy: 0.3395\n",
            "Epoch 32/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8759 - accuracy: 0.3752 - val_loss: 1.8939 - val_accuracy: 0.3686\n",
            "Epoch 33/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8584 - accuracy: 0.3806 - val_loss: 2.0041 - val_accuracy: 0.3276\n",
            "Epoch 34/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8512 - accuracy: 0.3848 - val_loss: 1.8932 - val_accuracy: 0.3625\n",
            "Epoch 35/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8378 - accuracy: 0.3901 - val_loss: 1.9047 - val_accuracy: 0.3656\n",
            "Epoch 36/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8309 - accuracy: 0.3925 - val_loss: 1.8585 - val_accuracy: 0.3593\n",
            "Epoch 37/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8193 - accuracy: 0.3986 - val_loss: 1.8525 - val_accuracy: 0.3650\n",
            "Epoch 38/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8062 - accuracy: 0.4000 - val_loss: 1.8584 - val_accuracy: 0.3772\n",
            "Epoch 39/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7982 - accuracy: 0.4025 - val_loss: 1.8254 - val_accuracy: 0.3880\n",
            "Epoch 40/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7908 - accuracy: 0.4044 - val_loss: 1.8771 - val_accuracy: 0.3796\n",
            "Epoch 41/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7799 - accuracy: 0.4091 - val_loss: 1.7983 - val_accuracy: 0.4043\n",
            "Epoch 42/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7739 - accuracy: 0.4125 - val_loss: 1.8153 - val_accuracy: 0.4003\n",
            "Epoch 43/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7650 - accuracy: 0.4157 - val_loss: 1.8262 - val_accuracy: 0.3961\n",
            "Epoch 44/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7562 - accuracy: 0.4188 - val_loss: 1.8315 - val_accuracy: 0.3844\n",
            "Epoch 45/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7500 - accuracy: 0.4192 - val_loss: 1.7511 - val_accuracy: 0.4206\n",
            "Epoch 46/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7361 - accuracy: 0.4242 - val_loss: 1.8457 - val_accuracy: 0.3730\n",
            "Epoch 47/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7357 - accuracy: 0.4246 - val_loss: 1.8128 - val_accuracy: 0.3919\n",
            "Epoch 48/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7264 - accuracy: 0.4302 - val_loss: 1.9459 - val_accuracy: 0.3337\n",
            "Epoch 49/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7221 - accuracy: 0.4299 - val_loss: 1.8181 - val_accuracy: 0.3839\n",
            "Epoch 50/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7159 - accuracy: 0.4311 - val_loss: 1.8632 - val_accuracy: 0.3650\n",
            "Epoch 51/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7075 - accuracy: 0.4340 - val_loss: 1.7423 - val_accuracy: 0.4104\n",
            "Epoch 52/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7013 - accuracy: 0.4360 - val_loss: 1.7436 - val_accuracy: 0.4154\n",
            "Epoch 53/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6949 - accuracy: 0.4387 - val_loss: 1.7081 - val_accuracy: 0.4354\n",
            "Epoch 54/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6894 - accuracy: 0.4397 - val_loss: 1.7522 - val_accuracy: 0.4186\n",
            "Epoch 55/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6816 - accuracy: 0.4442 - val_loss: 1.7944 - val_accuracy: 0.4043\n",
            "Epoch 56/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6776 - accuracy: 0.4463 - val_loss: 1.6998 - val_accuracy: 0.4329\n",
            "Epoch 57/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6701 - accuracy: 0.4490 - val_loss: 1.7244 - val_accuracy: 0.4280\n",
            "Epoch 58/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6632 - accuracy: 0.4518 - val_loss: 1.8125 - val_accuracy: 0.4008\n",
            "Epoch 59/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6644 - accuracy: 0.4517 - val_loss: 1.7430 - val_accuracy: 0.4123\n",
            "Epoch 60/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6525 - accuracy: 0.4535 - val_loss: 1.7247 - val_accuracy: 0.4266\n",
            "Epoch 61/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6513 - accuracy: 0.4543 - val_loss: 1.7129 - val_accuracy: 0.4236\n",
            "Epoch 62/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6490 - accuracy: 0.4544 - val_loss: 1.6973 - val_accuracy: 0.4372\n",
            "Epoch 63/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6423 - accuracy: 0.4592 - val_loss: 1.6639 - val_accuracy: 0.4574\n",
            "Epoch 64/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.6385 - accuracy: 0.4600 - val_loss: 1.8194 - val_accuracy: 0.3870\n",
            "Epoch 65/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6292 - accuracy: 0.4625 - val_loss: 1.6956 - val_accuracy: 0.4447\n",
            "Epoch 66/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6268 - accuracy: 0.4636 - val_loss: 1.6493 - val_accuracy: 0.4537\n",
            "Epoch 67/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.6215 - accuracy: 0.4665 - val_loss: 1.6689 - val_accuracy: 0.4526\n",
            "Epoch 68/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.6166 - accuracy: 0.4680 - val_loss: 1.6808 - val_accuracy: 0.4421\n",
            "Epoch 69/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6134 - accuracy: 0.4696 - val_loss: 1.7381 - val_accuracy: 0.4264\n",
            "Epoch 70/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6107 - accuracy: 0.4695 - val_loss: 1.6632 - val_accuracy: 0.4507\n",
            "Epoch 71/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6063 - accuracy: 0.4711 - val_loss: 1.6168 - val_accuracy: 0.4714\n",
            "Epoch 72/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5985 - accuracy: 0.4733 - val_loss: 1.6870 - val_accuracy: 0.4399\n",
            "Epoch 73/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5974 - accuracy: 0.4751 - val_loss: 1.6231 - val_accuracy: 0.4740\n",
            "Epoch 74/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5939 - accuracy: 0.4748 - val_loss: 1.6409 - val_accuracy: 0.4573\n",
            "Epoch 75/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5872 - accuracy: 0.4787 - val_loss: 1.6429 - val_accuracy: 0.4691\n",
            "Epoch 76/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5847 - accuracy: 0.4787 - val_loss: 1.6307 - val_accuracy: 0.4675\n",
            "Epoch 77/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5794 - accuracy: 0.4818 - val_loss: 1.7002 - val_accuracy: 0.4360\n",
            "Epoch 78/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5789 - accuracy: 0.4810 - val_loss: 1.5998 - val_accuracy: 0.4792\n",
            "Epoch 79/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5740 - accuracy: 0.4818 - val_loss: 1.6583 - val_accuracy: 0.4636\n",
            "Epoch 80/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5684 - accuracy: 0.4864 - val_loss: 1.6093 - val_accuracy: 0.4746\n",
            "Epoch 81/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5648 - accuracy: 0.4867 - val_loss: 1.6502 - val_accuracy: 0.4525\n",
            "Epoch 82/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5609 - accuracy: 0.4860 - val_loss: 1.6844 - val_accuracy: 0.4390\n",
            "Epoch 83/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5583 - accuracy: 0.4888 - val_loss: 1.6158 - val_accuracy: 0.4700\n",
            "Epoch 84/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5579 - accuracy: 0.4879 - val_loss: 1.6176 - val_accuracy: 0.4668\n",
            "Epoch 85/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5507 - accuracy: 0.4896 - val_loss: 1.6244 - val_accuracy: 0.4609\n",
            "Epoch 86/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5486 - accuracy: 0.4929 - val_loss: 1.5920 - val_accuracy: 0.4742\n",
            "Epoch 87/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5457 - accuracy: 0.4939 - val_loss: 1.6537 - val_accuracy: 0.4585\n",
            "Epoch 88/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5411 - accuracy: 0.4942 - val_loss: 1.6150 - val_accuracy: 0.4735\n",
            "Epoch 89/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5397 - accuracy: 0.4924 - val_loss: 1.6815 - val_accuracy: 0.4462\n",
            "Epoch 90/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5384 - accuracy: 0.4947 - val_loss: 1.6879 - val_accuracy: 0.4406\n",
            "Epoch 91/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5342 - accuracy: 0.4967 - val_loss: 1.6757 - val_accuracy: 0.4583\n",
            "Epoch 92/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5322 - accuracy: 0.4959 - val_loss: 1.5846 - val_accuracy: 0.4820\n",
            "Epoch 93/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5270 - accuracy: 0.4989 - val_loss: 1.6321 - val_accuracy: 0.4599\n",
            "Epoch 94/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5254 - accuracy: 0.4995 - val_loss: 1.6994 - val_accuracy: 0.4306\n",
            "Epoch 95/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5234 - accuracy: 0.5027 - val_loss: 1.5739 - val_accuracy: 0.4834\n",
            "Epoch 96/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5186 - accuracy: 0.5004 - val_loss: 1.5808 - val_accuracy: 0.4827\n",
            "Epoch 97/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5154 - accuracy: 0.5002 - val_loss: 1.6589 - val_accuracy: 0.4550\n",
            "Epoch 98/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5136 - accuracy: 0.5033 - val_loss: 1.6178 - val_accuracy: 0.4678\n",
            "Epoch 99/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5127 - accuracy: 0.5044 - val_loss: 1.5758 - val_accuracy: 0.4760\n",
            "Epoch 100/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5053 - accuracy: 0.5067 - val_loss: 1.6406 - val_accuracy: 0.4694\n",
            "Epoch 101/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5102 - accuracy: 0.5048 - val_loss: 1.5666 - val_accuracy: 0.4820\n",
            "Epoch 102/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.5050 - accuracy: 0.5076 - val_loss: 1.6164 - val_accuracy: 0.4625\n",
            "Epoch 103/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.5017 - accuracy: 0.5068 - val_loss: 1.6631 - val_accuracy: 0.4510\n",
            "Epoch 104/200\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 1.4967 - accuracy: 0.5104 - val_loss: 1.5701 - val_accuracy: 0.4799\n",
            "Epoch 105/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4945 - accuracy: 0.5094 - val_loss: 1.5985 - val_accuracy: 0.4775\n",
            "Epoch 106/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4943 - accuracy: 0.5101 - val_loss: 1.5621 - val_accuracy: 0.4870\n",
            "Epoch 107/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4914 - accuracy: 0.5115 - val_loss: 1.5948 - val_accuracy: 0.4752\n",
            "Epoch 108/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4904 - accuracy: 0.5122 - val_loss: 1.5766 - val_accuracy: 0.4796\n",
            "Epoch 109/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4876 - accuracy: 0.5130 - val_loss: 1.6439 - val_accuracy: 0.4503\n",
            "Epoch 110/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4841 - accuracy: 0.5130 - val_loss: 1.5899 - val_accuracy: 0.4792\n",
            "Epoch 111/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4831 - accuracy: 0.5143 - val_loss: 1.5453 - val_accuracy: 0.4976\n",
            "Epoch 112/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4801 - accuracy: 0.5148 - val_loss: 1.7067 - val_accuracy: 0.4393\n",
            "Epoch 113/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4765 - accuracy: 0.5180 - val_loss: 1.6375 - val_accuracy: 0.4634\n",
            "Epoch 114/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4740 - accuracy: 0.5168 - val_loss: 1.6346 - val_accuracy: 0.4603\n",
            "Epoch 115/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4751 - accuracy: 0.5169 - val_loss: 1.5597 - val_accuracy: 0.4834\n",
            "Epoch 116/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4728 - accuracy: 0.5166 - val_loss: 1.5235 - val_accuracy: 0.5063\n",
            "Epoch 117/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4703 - accuracy: 0.5182 - val_loss: 1.5293 - val_accuracy: 0.5028\n",
            "Epoch 118/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4691 - accuracy: 0.5200 - val_loss: 1.5158 - val_accuracy: 0.5120\n",
            "Epoch 119/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4622 - accuracy: 0.5220 - val_loss: 1.5470 - val_accuracy: 0.4913\n",
            "Epoch 120/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4610 - accuracy: 0.5226 - val_loss: 1.5350 - val_accuracy: 0.4983\n",
            "Epoch 121/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4594 - accuracy: 0.5233 - val_loss: 1.5878 - val_accuracy: 0.4827\n",
            "Epoch 122/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4576 - accuracy: 0.5236 - val_loss: 1.5080 - val_accuracy: 0.5055\n",
            "Epoch 123/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4576 - accuracy: 0.5233 - val_loss: 1.5378 - val_accuracy: 0.4951\n",
            "Epoch 124/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4547 - accuracy: 0.5243 - val_loss: 1.7004 - val_accuracy: 0.4249\n",
            "Epoch 125/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4554 - accuracy: 0.5238 - val_loss: 1.5448 - val_accuracy: 0.4932\n",
            "Epoch 126/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4506 - accuracy: 0.5261 - val_loss: 1.6334 - val_accuracy: 0.4702\n",
            "Epoch 127/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4480 - accuracy: 0.5270 - val_loss: 1.6119 - val_accuracy: 0.4712\n",
            "Epoch 128/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4457 - accuracy: 0.5269 - val_loss: 1.5671 - val_accuracy: 0.4799\n",
            "Epoch 129/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4445 - accuracy: 0.5254 - val_loss: 1.5598 - val_accuracy: 0.4889\n",
            "Epoch 130/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4437 - accuracy: 0.5264 - val_loss: 1.7587 - val_accuracy: 0.4370\n",
            "Epoch 131/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4438 - accuracy: 0.5277 - val_loss: 1.5215 - val_accuracy: 0.5061\n",
            "Epoch 132/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4367 - accuracy: 0.5309 - val_loss: 1.5225 - val_accuracy: 0.5001\n",
            "Epoch 133/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4390 - accuracy: 0.5285 - val_loss: 1.5448 - val_accuracy: 0.4944\n",
            "Epoch 134/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4375 - accuracy: 0.5286 - val_loss: 1.5893 - val_accuracy: 0.4795\n",
            "Epoch 135/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4340 - accuracy: 0.5299 - val_loss: 1.5143 - val_accuracy: 0.5029\n",
            "Epoch 136/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4341 - accuracy: 0.5306 - val_loss: 1.6163 - val_accuracy: 0.4790\n",
            "Epoch 137/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4290 - accuracy: 0.5313 - val_loss: 1.5662 - val_accuracy: 0.4744\n",
            "Epoch 138/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4334 - accuracy: 0.5301 - val_loss: 1.5369 - val_accuracy: 0.5039\n",
            "Epoch 139/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4290 - accuracy: 0.5326 - val_loss: 1.5122 - val_accuracy: 0.5100\n",
            "Epoch 140/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4264 - accuracy: 0.5334 - val_loss: 1.5528 - val_accuracy: 0.4977\n",
            "Epoch 141/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4275 - accuracy: 0.5327 - val_loss: 1.5350 - val_accuracy: 0.5025\n",
            "Epoch 142/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4252 - accuracy: 0.5351 - val_loss: 1.5187 - val_accuracy: 0.5033\n",
            "Epoch 143/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4223 - accuracy: 0.5341 - val_loss: 1.4942 - val_accuracy: 0.5181\n",
            "Epoch 144/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4209 - accuracy: 0.5359 - val_loss: 1.6186 - val_accuracy: 0.4610\n",
            "Epoch 145/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4165 - accuracy: 0.5381 - val_loss: 1.4912 - val_accuracy: 0.5177\n",
            "Epoch 146/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4179 - accuracy: 0.5360 - val_loss: 1.4899 - val_accuracy: 0.5158\n",
            "Epoch 147/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4168 - accuracy: 0.5364 - val_loss: 1.4780 - val_accuracy: 0.5162\n",
            "Epoch 148/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4129 - accuracy: 0.5380 - val_loss: 1.5144 - val_accuracy: 0.5073\n",
            "Epoch 149/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4122 - accuracy: 0.5402 - val_loss: 1.4920 - val_accuracy: 0.5190\n",
            "Epoch 150/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4113 - accuracy: 0.5376 - val_loss: 1.5367 - val_accuracy: 0.5016\n",
            "Epoch 151/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4084 - accuracy: 0.5419 - val_loss: 1.5039 - val_accuracy: 0.5116\n",
            "Epoch 152/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4108 - accuracy: 0.5387 - val_loss: 1.4753 - val_accuracy: 0.5206\n",
            "Epoch 153/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4060 - accuracy: 0.5405 - val_loss: 1.5522 - val_accuracy: 0.5027\n",
            "Epoch 154/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4049 - accuracy: 0.5424 - val_loss: 1.4796 - val_accuracy: 0.5204\n",
            "Epoch 155/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4043 - accuracy: 0.5403 - val_loss: 1.5373 - val_accuracy: 0.5063\n",
            "Epoch 156/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4019 - accuracy: 0.5418 - val_loss: 1.5388 - val_accuracy: 0.4948\n",
            "Epoch 157/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4013 - accuracy: 0.5436 - val_loss: 1.5403 - val_accuracy: 0.5029\n",
            "Epoch 158/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.4012 - accuracy: 0.5431 - val_loss: 1.4628 - val_accuracy: 0.5282\n",
            "Epoch 159/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3984 - accuracy: 0.5426 - val_loss: 1.5570 - val_accuracy: 0.4871\n",
            "Epoch 160/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3989 - accuracy: 0.5444 - val_loss: 1.5087 - val_accuracy: 0.5040\n",
            "Epoch 161/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3973 - accuracy: 0.5444 - val_loss: 1.5109 - val_accuracy: 0.5028\n",
            "Epoch 162/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3941 - accuracy: 0.5451 - val_loss: 1.6413 - val_accuracy: 0.4583\n",
            "Epoch 163/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3922 - accuracy: 0.5446 - val_loss: 1.4848 - val_accuracy: 0.5177\n",
            "Epoch 164/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3900 - accuracy: 0.5447 - val_loss: 1.4785 - val_accuracy: 0.5161\n",
            "Epoch 165/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3898 - accuracy: 0.5454 - val_loss: 1.5582 - val_accuracy: 0.5011\n",
            "Epoch 166/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3874 - accuracy: 0.5483 - val_loss: 1.4575 - val_accuracy: 0.5294\n",
            "Epoch 167/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3899 - accuracy: 0.5467 - val_loss: 1.5343 - val_accuracy: 0.4969\n",
            "Epoch 168/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3884 - accuracy: 0.5465 - val_loss: 1.5121 - val_accuracy: 0.5071\n",
            "Epoch 169/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3856 - accuracy: 0.5483 - val_loss: 1.4898 - val_accuracy: 0.5134\n",
            "Epoch 170/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3837 - accuracy: 0.5485 - val_loss: 1.5466 - val_accuracy: 0.4995\n",
            "Epoch 171/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3829 - accuracy: 0.5494 - val_loss: 1.5583 - val_accuracy: 0.4991\n",
            "Epoch 172/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3855 - accuracy: 0.5478 - val_loss: 1.5612 - val_accuracy: 0.4972\n",
            "Epoch 173/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3827 - accuracy: 0.5483 - val_loss: 1.5949 - val_accuracy: 0.4836\n",
            "Epoch 174/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3818 - accuracy: 0.5509 - val_loss: 1.4855 - val_accuracy: 0.5222\n",
            "Epoch 175/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3807 - accuracy: 0.5483 - val_loss: 1.4693 - val_accuracy: 0.5254\n",
            "Epoch 176/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3769 - accuracy: 0.5523 - val_loss: 1.4763 - val_accuracy: 0.5181\n",
            "Epoch 177/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3775 - accuracy: 0.5521 - val_loss: 1.4545 - val_accuracy: 0.5316\n",
            "Epoch 178/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3772 - accuracy: 0.5495 - val_loss: 1.5763 - val_accuracy: 0.4900\n",
            "Epoch 179/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3727 - accuracy: 0.5525 - val_loss: 1.5108 - val_accuracy: 0.5165\n",
            "Epoch 180/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3722 - accuracy: 0.5531 - val_loss: 1.5436 - val_accuracy: 0.4976\n",
            "Epoch 181/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3734 - accuracy: 0.5500 - val_loss: 1.4714 - val_accuracy: 0.5248\n",
            "Epoch 182/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3693 - accuracy: 0.5536 - val_loss: 1.4816 - val_accuracy: 0.5305\n",
            "Epoch 183/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3712 - accuracy: 0.5541 - val_loss: 1.6343 - val_accuracy: 0.4587\n",
            "Epoch 184/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3706 - accuracy: 0.5524 - val_loss: 1.4563 - val_accuracy: 0.5361\n",
            "Epoch 185/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3678 - accuracy: 0.5553 - val_loss: 1.4540 - val_accuracy: 0.5340\n",
            "Epoch 186/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3683 - accuracy: 0.5562 - val_loss: 1.5006 - val_accuracy: 0.5241\n",
            "Epoch 187/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3656 - accuracy: 0.5552 - val_loss: 1.4669 - val_accuracy: 0.5313\n",
            "Epoch 188/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3642 - accuracy: 0.5554 - val_loss: 1.4631 - val_accuracy: 0.5241\n",
            "Epoch 189/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3628 - accuracy: 0.5573 - val_loss: 1.5226 - val_accuracy: 0.5081\n",
            "Epoch 190/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3655 - accuracy: 0.5557 - val_loss: 1.4785 - val_accuracy: 0.5300\n",
            "Epoch 191/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3633 - accuracy: 0.5565 - val_loss: 1.5133 - val_accuracy: 0.5055\n",
            "Epoch 192/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3592 - accuracy: 0.5570 - val_loss: 1.4983 - val_accuracy: 0.5115\n",
            "Epoch 193/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3628 - accuracy: 0.5570 - val_loss: 1.4686 - val_accuracy: 0.5305\n",
            "Epoch 194/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3581 - accuracy: 0.5596 - val_loss: 1.5451 - val_accuracy: 0.4987\n",
            "Epoch 195/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3585 - accuracy: 0.5569 - val_loss: 1.4777 - val_accuracy: 0.5225\n",
            "Epoch 196/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3589 - accuracy: 0.5571 - val_loss: 1.5059 - val_accuracy: 0.5005\n",
            "Epoch 197/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3564 - accuracy: 0.5574 - val_loss: 1.4988 - val_accuracy: 0.5068\n",
            "Epoch 198/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3558 - accuracy: 0.5608 - val_loss: 1.4827 - val_accuracy: 0.5156\n",
            "Epoch 199/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3520 - accuracy: 0.5589 - val_loss: 1.5078 - val_accuracy: 0.5067\n",
            "Epoch 200/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.3520 - accuracy: 0.5614 - val_loss: 1.4492 - val_accuracy: 0.5413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd36420b8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfGY2PD-5gnh",
        "outputId": "755892e5-8038-4514-f8b5-19a8029bb28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step - loss: 1.4712 - accuracy: 0.5338\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.47124183177948, 0.5338215827941895]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora com PCA"
      ],
      "metadata": {
        "id": "SP0_6YjRSw04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, activation='tanh', input_shape=(30,)))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-6A_yutVuuL",
        "outputId": "fcc4ce21-78d8-42f8-a434-7ead08dfd0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 18)                558       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,488\n",
            "Trainable params: 1,488\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])\n",
        "model.fit(X_train_scaled_pca, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid_scaled_pca, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p34633kjV0_C",
        "outputId": "806fd933-7710-4057-b311-7f2ddf273206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.5629 - accuracy: 0.1465 - val_loss: 2.4064 - val_accuracy: 0.1908\n",
            "Epoch 2/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.3641 - accuracy: 0.2029 - val_loss: 2.3207 - val_accuracy: 0.2197\n",
            "Epoch 3/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.3029 - accuracy: 0.2226 - val_loss: 2.2782 - val_accuracy: 0.2244\n",
            "Epoch 4/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2629 - accuracy: 0.2359 - val_loss: 2.2439 - val_accuracy: 0.2419\n",
            "Epoch 5/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2325 - accuracy: 0.2539 - val_loss: 2.2192 - val_accuracy: 0.2614\n",
            "Epoch 6/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.2081 - accuracy: 0.2644 - val_loss: 2.1980 - val_accuracy: 0.2638\n",
            "Epoch 7/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1876 - accuracy: 0.2746 - val_loss: 2.1769 - val_accuracy: 0.2762\n",
            "Epoch 8/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1687 - accuracy: 0.2835 - val_loss: 2.1618 - val_accuracy: 0.2866\n",
            "Epoch 9/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1513 - accuracy: 0.2902 - val_loss: 2.1482 - val_accuracy: 0.2872\n",
            "Epoch 10/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1344 - accuracy: 0.2956 - val_loss: 2.1332 - val_accuracy: 0.2956\n",
            "Epoch 11/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1182 - accuracy: 0.3016 - val_loss: 2.1161 - val_accuracy: 0.3028\n",
            "Epoch 12/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.1020 - accuracy: 0.3091 - val_loss: 2.1038 - val_accuracy: 0.3079\n",
            "Epoch 13/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0862 - accuracy: 0.3142 - val_loss: 2.0847 - val_accuracy: 0.3164\n",
            "Epoch 14/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0701 - accuracy: 0.3212 - val_loss: 2.0766 - val_accuracy: 0.3164\n",
            "Epoch 15/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0549 - accuracy: 0.3266 - val_loss: 2.0591 - val_accuracy: 0.3246\n",
            "Epoch 16/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0397 - accuracy: 0.3331 - val_loss: 2.0498 - val_accuracy: 0.3340\n",
            "Epoch 17/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0249 - accuracy: 0.3374 - val_loss: 2.0337 - val_accuracy: 0.3372\n",
            "Epoch 18/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 2.0109 - accuracy: 0.3433 - val_loss: 2.0201 - val_accuracy: 0.3422\n",
            "Epoch 19/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9971 - accuracy: 0.3476 - val_loss: 2.0129 - val_accuracy: 0.3427\n",
            "Epoch 20/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9838 - accuracy: 0.3501 - val_loss: 1.9965 - val_accuracy: 0.3457\n",
            "Epoch 21/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9713 - accuracy: 0.3562 - val_loss: 1.9883 - val_accuracy: 0.3503\n",
            "Epoch 22/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9591 - accuracy: 0.3596 - val_loss: 1.9766 - val_accuracy: 0.3549\n",
            "Epoch 23/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9476 - accuracy: 0.3639 - val_loss: 1.9709 - val_accuracy: 0.3478\n",
            "Epoch 24/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9370 - accuracy: 0.3671 - val_loss: 1.9596 - val_accuracy: 0.3617\n",
            "Epoch 25/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9267 - accuracy: 0.3705 - val_loss: 1.9504 - val_accuracy: 0.3618\n",
            "Epoch 26/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9166 - accuracy: 0.3730 - val_loss: 1.9420 - val_accuracy: 0.3696\n",
            "Epoch 27/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.9080 - accuracy: 0.3765 - val_loss: 1.9326 - val_accuracy: 0.3732\n",
            "Epoch 28/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8993 - accuracy: 0.3790 - val_loss: 1.9216 - val_accuracy: 0.3774\n",
            "Epoch 29/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8914 - accuracy: 0.3816 - val_loss: 1.9231 - val_accuracy: 0.3763\n",
            "Epoch 30/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8835 - accuracy: 0.3831 - val_loss: 1.9155 - val_accuracy: 0.3771\n",
            "Epoch 31/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8764 - accuracy: 0.3846 - val_loss: 1.9052 - val_accuracy: 0.3870\n",
            "Epoch 32/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8695 - accuracy: 0.3886 - val_loss: 1.9063 - val_accuracy: 0.3794\n",
            "Epoch 33/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8628 - accuracy: 0.3893 - val_loss: 1.8958 - val_accuracy: 0.3875\n",
            "Epoch 34/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8567 - accuracy: 0.3907 - val_loss: 1.8936 - val_accuracy: 0.3852\n",
            "Epoch 35/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8508 - accuracy: 0.3933 - val_loss: 1.8832 - val_accuracy: 0.3881\n",
            "Epoch 36/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8449 - accuracy: 0.3945 - val_loss: 1.8749 - val_accuracy: 0.3900\n",
            "Epoch 37/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8396 - accuracy: 0.3977 - val_loss: 1.8862 - val_accuracy: 0.3868\n",
            "Epoch 38/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8344 - accuracy: 0.3996 - val_loss: 1.8777 - val_accuracy: 0.3901\n",
            "Epoch 39/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8292 - accuracy: 0.4017 - val_loss: 1.8662 - val_accuracy: 0.3955\n",
            "Epoch 40/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8248 - accuracy: 0.4030 - val_loss: 1.8609 - val_accuracy: 0.3956\n",
            "Epoch 41/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8205 - accuracy: 0.4047 - val_loss: 1.8587 - val_accuracy: 0.4009\n",
            "Epoch 42/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8161 - accuracy: 0.4048 - val_loss: 1.8611 - val_accuracy: 0.3985\n",
            "Epoch 43/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8119 - accuracy: 0.4070 - val_loss: 1.8551 - val_accuracy: 0.3969\n",
            "Epoch 44/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8074 - accuracy: 0.4088 - val_loss: 1.8549 - val_accuracy: 0.3929\n",
            "Epoch 45/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8041 - accuracy: 0.4088 - val_loss: 1.8504 - val_accuracy: 0.3956\n",
            "Epoch 46/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.8004 - accuracy: 0.4116 - val_loss: 1.8450 - val_accuracy: 0.4052\n",
            "Epoch 47/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7970 - accuracy: 0.4128 - val_loss: 1.8468 - val_accuracy: 0.3997\n",
            "Epoch 48/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7939 - accuracy: 0.4128 - val_loss: 1.8400 - val_accuracy: 0.4049\n",
            "Epoch 49/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7907 - accuracy: 0.4138 - val_loss: 1.8309 - val_accuracy: 0.4080\n",
            "Epoch 50/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7874 - accuracy: 0.4139 - val_loss: 1.8344 - val_accuracy: 0.4101\n",
            "Epoch 51/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7851 - accuracy: 0.4163 - val_loss: 1.8389 - val_accuracy: 0.4021\n",
            "Epoch 52/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7822 - accuracy: 0.4156 - val_loss: 1.8285 - val_accuracy: 0.4055\n",
            "Epoch 53/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7794 - accuracy: 0.4161 - val_loss: 1.8317 - val_accuracy: 0.4071\n",
            "Epoch 54/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7770 - accuracy: 0.4180 - val_loss: 1.8321 - val_accuracy: 0.4047\n",
            "Epoch 55/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7743 - accuracy: 0.4177 - val_loss: 1.8287 - val_accuracy: 0.4084\n",
            "Epoch 56/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7723 - accuracy: 0.4189 - val_loss: 1.8270 - val_accuracy: 0.4044\n",
            "Epoch 57/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7697 - accuracy: 0.4208 - val_loss: 1.8249 - val_accuracy: 0.4095\n",
            "Epoch 58/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7676 - accuracy: 0.4211 - val_loss: 1.8192 - val_accuracy: 0.4141\n",
            "Epoch 59/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7648 - accuracy: 0.4213 - val_loss: 1.8195 - val_accuracy: 0.4105\n",
            "Epoch 60/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7633 - accuracy: 0.4237 - val_loss: 1.8185 - val_accuracy: 0.4088\n",
            "Epoch 61/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7608 - accuracy: 0.4228 - val_loss: 1.8163 - val_accuracy: 0.4119\n",
            "Epoch 62/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7590 - accuracy: 0.4230 - val_loss: 1.8130 - val_accuracy: 0.4146\n",
            "Epoch 63/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7570 - accuracy: 0.4244 - val_loss: 1.8195 - val_accuracy: 0.4065\n",
            "Epoch 64/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7549 - accuracy: 0.4242 - val_loss: 1.8161 - val_accuracy: 0.4140\n",
            "Epoch 65/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7530 - accuracy: 0.4269 - val_loss: 1.8074 - val_accuracy: 0.4152\n",
            "Epoch 66/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7507 - accuracy: 0.4270 - val_loss: 1.8176 - val_accuracy: 0.4132\n",
            "Epoch 67/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7495 - accuracy: 0.4279 - val_loss: 1.8045 - val_accuracy: 0.4161\n",
            "Epoch 68/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7475 - accuracy: 0.4278 - val_loss: 1.8000 - val_accuracy: 0.4197\n",
            "Epoch 69/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7456 - accuracy: 0.4284 - val_loss: 1.8041 - val_accuracy: 0.4174\n",
            "Epoch 70/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7436 - accuracy: 0.4302 - val_loss: 1.8084 - val_accuracy: 0.4141\n",
            "Epoch 71/200\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 1.7421 - accuracy: 0.4303 - val_loss: 1.8082 - val_accuracy: 0.4157\n",
            "Epoch 72/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7408 - accuracy: 0.4310 - val_loss: 1.8024 - val_accuracy: 0.4194\n",
            "Epoch 73/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.7389 - accuracy: 0.4301 - val_loss: 1.8013 - val_accuracy: 0.4178\n",
            "Epoch 74/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7372 - accuracy: 0.4323 - val_loss: 1.8000 - val_accuracy: 0.4229\n",
            "Epoch 75/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7356 - accuracy: 0.4331 - val_loss: 1.8012 - val_accuracy: 0.4196\n",
            "Epoch 76/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.7339 - accuracy: 0.4327 - val_loss: 1.7993 - val_accuracy: 0.4213\n",
            "Epoch 77/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.7322 - accuracy: 0.4336 - val_loss: 1.7950 - val_accuracy: 0.4240\n",
            "Epoch 78/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.7303 - accuracy: 0.4348 - val_loss: 1.8031 - val_accuracy: 0.4216\n",
            "Epoch 79/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7292 - accuracy: 0.4350 - val_loss: 1.8043 - val_accuracy: 0.4130\n",
            "Epoch 80/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7276 - accuracy: 0.4341 - val_loss: 1.7900 - val_accuracy: 0.4216\n",
            "Epoch 81/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.7265 - accuracy: 0.4363 - val_loss: 1.8072 - val_accuracy: 0.4150\n",
            "Epoch 82/200\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 1.7250 - accuracy: 0.4369 - val_loss: 1.7954 - val_accuracy: 0.4213\n",
            "Epoch 83/200\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.7235 - accuracy: 0.4374 - val_loss: 1.7894 - val_accuracy: 0.4197\n",
            "Epoch 84/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7221 - accuracy: 0.4382 - val_loss: 1.7996 - val_accuracy: 0.4176\n",
            "Epoch 85/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7208 - accuracy: 0.4373 - val_loss: 1.7904 - val_accuracy: 0.4220\n",
            "Epoch 86/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7194 - accuracy: 0.4388 - val_loss: 1.7939 - val_accuracy: 0.4201\n",
            "Epoch 87/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7183 - accuracy: 0.4386 - val_loss: 1.7866 - val_accuracy: 0.4222\n",
            "Epoch 88/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7164 - accuracy: 0.4386 - val_loss: 1.7923 - val_accuracy: 0.4220\n",
            "Epoch 89/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.7156 - accuracy: 0.4400 - val_loss: 1.7872 - val_accuracy: 0.4248\n",
            "Epoch 90/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7143 - accuracy: 0.4400 - val_loss: 1.7882 - val_accuracy: 0.4214\n",
            "Epoch 91/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7126 - accuracy: 0.4408 - val_loss: 1.7789 - val_accuracy: 0.4205\n",
            "Epoch 92/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7119 - accuracy: 0.4422 - val_loss: 1.7783 - val_accuracy: 0.4246\n",
            "Epoch 93/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7105 - accuracy: 0.4409 - val_loss: 1.7789 - val_accuracy: 0.4272\n",
            "Epoch 94/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7091 - accuracy: 0.4431 - val_loss: 1.7855 - val_accuracy: 0.4234\n",
            "Epoch 95/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7086 - accuracy: 0.4422 - val_loss: 1.7810 - val_accuracy: 0.4244\n",
            "Epoch 96/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7068 - accuracy: 0.4425 - val_loss: 1.7780 - val_accuracy: 0.4232\n",
            "Epoch 97/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7059 - accuracy: 0.4431 - val_loss: 1.7806 - val_accuracy: 0.4265\n",
            "Epoch 98/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7046 - accuracy: 0.4424 - val_loss: 1.7811 - val_accuracy: 0.4258\n",
            "Epoch 99/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7033 - accuracy: 0.4447 - val_loss: 1.7792 - val_accuracy: 0.4252\n",
            "Epoch 100/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7022 - accuracy: 0.4439 - val_loss: 1.7704 - val_accuracy: 0.4272\n",
            "Epoch 101/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.7011 - accuracy: 0.4453 - val_loss: 1.7701 - val_accuracy: 0.4304\n",
            "Epoch 102/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6996 - accuracy: 0.4466 - val_loss: 1.7793 - val_accuracy: 0.4262\n",
            "Epoch 103/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6987 - accuracy: 0.4446 - val_loss: 1.7736 - val_accuracy: 0.4297\n",
            "Epoch 104/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6976 - accuracy: 0.4452 - val_loss: 1.7766 - val_accuracy: 0.4249\n",
            "Epoch 105/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6967 - accuracy: 0.4445 - val_loss: 1.7605 - val_accuracy: 0.4300\n",
            "Epoch 106/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6961 - accuracy: 0.4470 - val_loss: 1.7703 - val_accuracy: 0.4250\n",
            "Epoch 107/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6949 - accuracy: 0.4456 - val_loss: 1.7671 - val_accuracy: 0.4313\n",
            "Epoch 108/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6934 - accuracy: 0.4467 - val_loss: 1.7654 - val_accuracy: 0.4273\n",
            "Epoch 109/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6925 - accuracy: 0.4475 - val_loss: 1.7672 - val_accuracy: 0.4281\n",
            "Epoch 110/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6916 - accuracy: 0.4480 - val_loss: 1.7662 - val_accuracy: 0.4260\n",
            "Epoch 111/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6905 - accuracy: 0.4483 - val_loss: 1.7704 - val_accuracy: 0.4286\n",
            "Epoch 112/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6893 - accuracy: 0.4488 - val_loss: 1.7625 - val_accuracy: 0.4264\n",
            "Epoch 113/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6883 - accuracy: 0.4477 - val_loss: 1.7557 - val_accuracy: 0.4362\n",
            "Epoch 114/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6876 - accuracy: 0.4490 - val_loss: 1.7548 - val_accuracy: 0.4345\n",
            "Epoch 115/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6862 - accuracy: 0.4488 - val_loss: 1.7653 - val_accuracy: 0.4293\n",
            "Epoch 116/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6855 - accuracy: 0.4499 - val_loss: 1.7569 - val_accuracy: 0.4290\n",
            "Epoch 117/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6847 - accuracy: 0.4498 - val_loss: 1.7649 - val_accuracy: 0.4286\n",
            "Epoch 118/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6834 - accuracy: 0.4507 - val_loss: 1.7630 - val_accuracy: 0.4298\n",
            "Epoch 119/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6829 - accuracy: 0.4514 - val_loss: 1.7713 - val_accuracy: 0.4250\n",
            "Epoch 120/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6815 - accuracy: 0.4513 - val_loss: 1.7624 - val_accuracy: 0.4260\n",
            "Epoch 121/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6813 - accuracy: 0.4505 - val_loss: 1.7538 - val_accuracy: 0.4358\n",
            "Epoch 122/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6799 - accuracy: 0.4516 - val_loss: 1.7588 - val_accuracy: 0.4317\n",
            "Epoch 123/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6786 - accuracy: 0.4523 - val_loss: 1.7665 - val_accuracy: 0.4320\n",
            "Epoch 124/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6787 - accuracy: 0.4515 - val_loss: 1.7601 - val_accuracy: 0.4285\n",
            "Epoch 125/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6773 - accuracy: 0.4523 - val_loss: 1.7601 - val_accuracy: 0.4300\n",
            "Epoch 126/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6773 - accuracy: 0.4530 - val_loss: 1.7560 - val_accuracy: 0.4341\n",
            "Epoch 127/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6755 - accuracy: 0.4528 - val_loss: 1.7630 - val_accuracy: 0.4304\n",
            "Epoch 128/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6750 - accuracy: 0.4536 - val_loss: 1.7528 - val_accuracy: 0.4313\n",
            "Epoch 129/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6746 - accuracy: 0.4532 - val_loss: 1.7462 - val_accuracy: 0.4348\n",
            "Epoch 130/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6735 - accuracy: 0.4546 - val_loss: 1.7613 - val_accuracy: 0.4328\n",
            "Epoch 131/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6731 - accuracy: 0.4560 - val_loss: 1.7526 - val_accuracy: 0.4338\n",
            "Epoch 132/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6718 - accuracy: 0.4541 - val_loss: 1.7521 - val_accuracy: 0.4322\n",
            "Epoch 133/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6712 - accuracy: 0.4550 - val_loss: 1.7459 - val_accuracy: 0.4320\n",
            "Epoch 134/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6710 - accuracy: 0.4561 - val_loss: 1.7434 - val_accuracy: 0.4358\n",
            "Epoch 135/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6699 - accuracy: 0.4549 - val_loss: 1.7679 - val_accuracy: 0.4289\n",
            "Epoch 136/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6698 - accuracy: 0.4552 - val_loss: 1.7509 - val_accuracy: 0.4381\n",
            "Epoch 137/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6685 - accuracy: 0.4561 - val_loss: 1.7496 - val_accuracy: 0.4337\n",
            "Epoch 138/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6679 - accuracy: 0.4553 - val_loss: 1.7539 - val_accuracy: 0.4362\n",
            "Epoch 139/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6673 - accuracy: 0.4569 - val_loss: 1.7428 - val_accuracy: 0.4370\n",
            "Epoch 140/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6666 - accuracy: 0.4554 - val_loss: 1.7511 - val_accuracy: 0.4340\n",
            "Epoch 141/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6659 - accuracy: 0.4571 - val_loss: 1.7345 - val_accuracy: 0.4403\n",
            "Epoch 142/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6650 - accuracy: 0.4575 - val_loss: 1.7552 - val_accuracy: 0.4333\n",
            "Epoch 143/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6646 - accuracy: 0.4574 - val_loss: 1.7455 - val_accuracy: 0.4368\n",
            "Epoch 144/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6640 - accuracy: 0.4578 - val_loss: 1.7430 - val_accuracy: 0.4374\n",
            "Epoch 145/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6633 - accuracy: 0.4568 - val_loss: 1.7608 - val_accuracy: 0.4270\n",
            "Epoch 146/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6626 - accuracy: 0.4590 - val_loss: 1.7460 - val_accuracy: 0.4361\n",
            "Epoch 147/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6619 - accuracy: 0.4585 - val_loss: 1.7469 - val_accuracy: 0.4328\n",
            "Epoch 148/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6618 - accuracy: 0.4585 - val_loss: 1.7424 - val_accuracy: 0.4342\n",
            "Epoch 149/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6612 - accuracy: 0.4584 - val_loss: 1.7417 - val_accuracy: 0.4325\n",
            "Epoch 150/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6605 - accuracy: 0.4593 - val_loss: 1.7401 - val_accuracy: 0.4344\n",
            "Epoch 151/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6598 - accuracy: 0.4599 - val_loss: 1.7410 - val_accuracy: 0.4374\n",
            "Epoch 152/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6596 - accuracy: 0.4591 - val_loss: 1.7395 - val_accuracy: 0.4364\n",
            "Epoch 153/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6590 - accuracy: 0.4609 - val_loss: 1.7398 - val_accuracy: 0.4383\n",
            "Epoch 154/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6582 - accuracy: 0.4600 - val_loss: 1.7518 - val_accuracy: 0.4320\n",
            "Epoch 155/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6573 - accuracy: 0.4609 - val_loss: 1.7312 - val_accuracy: 0.4382\n",
            "Epoch 156/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6571 - accuracy: 0.4614 - val_loss: 1.7479 - val_accuracy: 0.4389\n",
            "Epoch 157/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6563 - accuracy: 0.4605 - val_loss: 1.7351 - val_accuracy: 0.4383\n",
            "Epoch 158/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6563 - accuracy: 0.4608 - val_loss: 1.7427 - val_accuracy: 0.4378\n",
            "Epoch 159/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6553 - accuracy: 0.4615 - val_loss: 1.7303 - val_accuracy: 0.4402\n",
            "Epoch 160/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6551 - accuracy: 0.4607 - val_loss: 1.7453 - val_accuracy: 0.4345\n",
            "Epoch 161/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6543 - accuracy: 0.4612 - val_loss: 1.7300 - val_accuracy: 0.4407\n",
            "Epoch 162/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6543 - accuracy: 0.4622 - val_loss: 1.7336 - val_accuracy: 0.4381\n",
            "Epoch 163/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6530 - accuracy: 0.4603 - val_loss: 1.7320 - val_accuracy: 0.4405\n",
            "Epoch 164/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6529 - accuracy: 0.4618 - val_loss: 1.7387 - val_accuracy: 0.4395\n",
            "Epoch 165/200\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 1.6522 - accuracy: 0.4632 - val_loss: 1.7386 - val_accuracy: 0.4381\n",
            "Epoch 166/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6512 - accuracy: 0.4626 - val_loss: 1.7353 - val_accuracy: 0.4423\n",
            "Epoch 167/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6510 - accuracy: 0.4624 - val_loss: 1.7390 - val_accuracy: 0.4345\n",
            "Epoch 168/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6505 - accuracy: 0.4629 - val_loss: 1.7348 - val_accuracy: 0.4369\n",
            "Epoch 169/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6497 - accuracy: 0.4618 - val_loss: 1.7492 - val_accuracy: 0.4321\n",
            "Epoch 170/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6497 - accuracy: 0.4631 - val_loss: 1.7281 - val_accuracy: 0.4418\n",
            "Epoch 171/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6490 - accuracy: 0.4629 - val_loss: 1.7354 - val_accuracy: 0.4398\n",
            "Epoch 172/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6490 - accuracy: 0.4619 - val_loss: 1.7334 - val_accuracy: 0.4399\n",
            "Epoch 173/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6480 - accuracy: 0.4640 - val_loss: 1.7281 - val_accuracy: 0.4386\n",
            "Epoch 174/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6475 - accuracy: 0.4626 - val_loss: 1.7232 - val_accuracy: 0.4415\n",
            "Epoch 175/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6472 - accuracy: 0.4634 - val_loss: 1.7376 - val_accuracy: 0.4445\n",
            "Epoch 176/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6468 - accuracy: 0.4630 - val_loss: 1.7241 - val_accuracy: 0.4402\n",
            "Epoch 177/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6463 - accuracy: 0.4654 - val_loss: 1.7359 - val_accuracy: 0.4372\n",
            "Epoch 178/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6456 - accuracy: 0.4637 - val_loss: 1.7365 - val_accuracy: 0.4402\n",
            "Epoch 179/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6446 - accuracy: 0.4639 - val_loss: 1.7378 - val_accuracy: 0.4426\n",
            "Epoch 180/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6446 - accuracy: 0.4641 - val_loss: 1.7226 - val_accuracy: 0.4414\n",
            "Epoch 181/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6442 - accuracy: 0.4640 - val_loss: 1.7274 - val_accuracy: 0.4435\n",
            "Epoch 182/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6433 - accuracy: 0.4647 - val_loss: 1.7312 - val_accuracy: 0.4401\n",
            "Epoch 183/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6433 - accuracy: 0.4638 - val_loss: 1.7334 - val_accuracy: 0.4398\n",
            "Epoch 184/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6430 - accuracy: 0.4641 - val_loss: 1.7358 - val_accuracy: 0.4398\n",
            "Epoch 185/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6427 - accuracy: 0.4642 - val_loss: 1.7287 - val_accuracy: 0.4368\n",
            "Epoch 186/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6419 - accuracy: 0.4641 - val_loss: 1.7319 - val_accuracy: 0.4433\n",
            "Epoch 187/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6416 - accuracy: 0.4648 - val_loss: 1.7277 - val_accuracy: 0.4417\n",
            "Epoch 188/200\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.6408 - accuracy: 0.4650 - val_loss: 1.7203 - val_accuracy: 0.4438\n",
            "Epoch 189/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6409 - accuracy: 0.4657 - val_loss: 1.7258 - val_accuracy: 0.4398\n",
            "Epoch 190/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6402 - accuracy: 0.4650 - val_loss: 1.7283 - val_accuracy: 0.4379\n",
            "Epoch 191/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6395 - accuracy: 0.4655 - val_loss: 1.7154 - val_accuracy: 0.4443\n",
            "Epoch 192/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6395 - accuracy: 0.4649 - val_loss: 1.7179 - val_accuracy: 0.4441\n",
            "Epoch 193/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6387 - accuracy: 0.4649 - val_loss: 1.7126 - val_accuracy: 0.4482\n",
            "Epoch 194/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6386 - accuracy: 0.4663 - val_loss: 1.7227 - val_accuracy: 0.4401\n",
            "Epoch 195/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6383 - accuracy: 0.4655 - val_loss: 1.7228 - val_accuracy: 0.4489\n",
            "Epoch 196/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6373 - accuracy: 0.4649 - val_loss: 1.7219 - val_accuracy: 0.4449\n",
            "Epoch 197/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6370 - accuracy: 0.4655 - val_loss: 1.7186 - val_accuracy: 0.4433\n",
            "Epoch 198/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6364 - accuracy: 0.4657 - val_loss: 1.7181 - val_accuracy: 0.4466\n",
            "Epoch 199/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6359 - accuracy: 0.4659 - val_loss: 1.7196 - val_accuracy: 0.4449\n",
            "Epoch 200/200\n",
            "470/470 [==============================] - 1s 2ms/step - loss: 1.6357 - accuracy: 0.4664 - val_loss: 1.7167 - val_accuracy: 0.4481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd352334bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled_pca, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTDufdpeZIp2",
        "outputId": "5192543a-3487-4224-922f-be6f472ab105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 7ms/step - loss: 1.7006 - accuracy: 0.4451\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7006258964538574, 0.4451398253440857]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aLaeBMPz8mXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste com Perceprton Multicamada"
      ],
      "metadata": {
        "id": "tPtH5QiU9vtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(92, activation='relu', input_shape=(92,)))\n",
        "model.add(Dense(92, activation='relu'))\n",
        "model.add(Dense(92, activation='relu'))\n",
        "model.add(Dense(92, activation='relu'))\n",
        "model.add(Dense(92, activation='relu'))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mtbl7aJ-J8g",
        "outputId": "30685714-4315-4d0e-b48b-5031b6704d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 92)                8556      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 92)                8556      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 92)                8556      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 92)                8556      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 92)                8556      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 18)                1674      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,454\n",
            "Trainable params: 44,454\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.1), metrics=['accuracy'])\n",
        "model.fit(X_train_scaled, y_train, batch_size=128, epochs=50, verbose=1, validation_data=(X_valid_scaled, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63m6Jj38-XcJ",
        "outputId": "561a8a60-0947-4fb7-a5a5-cb294ff2b2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 0.6650 - accuracy: 0.7768 - val_loss: 1.3628 - val_accuracy: 0.6314\n",
            "Epoch 2/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6540 - accuracy: 0.7816 - val_loss: 1.4278 - val_accuracy: 0.6338\n",
            "Epoch 3/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6540 - accuracy: 0.7808 - val_loss: 1.3231 - val_accuracy: 0.6499\n",
            "Epoch 4/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6571 - accuracy: 0.7818 - val_loss: 1.3578 - val_accuracy: 0.6441\n",
            "Epoch 5/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6491 - accuracy: 0.7831 - val_loss: 1.4647 - val_accuracy: 0.6224\n",
            "Epoch 6/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6538 - accuracy: 0.7814 - val_loss: 1.4236 - val_accuracy: 0.6236\n",
            "Epoch 7/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6450 - accuracy: 0.7846 - val_loss: 1.3189 - val_accuracy: 0.6550\n",
            "Epoch 8/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6507 - accuracy: 0.7827 - val_loss: 1.5309 - val_accuracy: 0.5984\n",
            "Epoch 9/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6471 - accuracy: 0.7841 - val_loss: 1.4556 - val_accuracy: 0.6181\n",
            "Epoch 10/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6513 - accuracy: 0.7809 - val_loss: 1.3576 - val_accuracy: 0.6442\n",
            "Epoch 11/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6492 - accuracy: 0.7822 - val_loss: 1.6261 - val_accuracy: 0.5880\n",
            "Epoch 12/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6482 - accuracy: 0.7826 - val_loss: 1.4994 - val_accuracy: 0.6028\n",
            "Epoch 13/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6460 - accuracy: 0.7845 - val_loss: 1.4800 - val_accuracy: 0.6146\n",
            "Epoch 14/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6351 - accuracy: 0.7864 - val_loss: 1.6105 - val_accuracy: 0.6020\n",
            "Epoch 15/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6422 - accuracy: 0.7851 - val_loss: 1.8160 - val_accuracy: 0.5589\n",
            "Epoch 16/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6374 - accuracy: 0.7872 - val_loss: 1.5997 - val_accuracy: 0.6000\n",
            "Epoch 17/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6437 - accuracy: 0.7818 - val_loss: 1.4194 - val_accuracy: 0.6381\n",
            "Epoch 18/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6450 - accuracy: 0.7830 - val_loss: 1.4907 - val_accuracy: 0.6117\n",
            "Epoch 19/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6333 - accuracy: 0.7864 - val_loss: 1.3362 - val_accuracy: 0.6514\n",
            "Epoch 20/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6405 - accuracy: 0.7881 - val_loss: 1.3673 - val_accuracy: 0.6382\n",
            "Epoch 21/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6205 - accuracy: 0.7918 - val_loss: 1.2818 - val_accuracy: 0.6662\n",
            "Epoch 22/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6294 - accuracy: 0.7878 - val_loss: 1.5924 - val_accuracy: 0.6029\n",
            "Epoch 23/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6350 - accuracy: 0.7870 - val_loss: 1.4606 - val_accuracy: 0.6289\n",
            "Epoch 24/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6375 - accuracy: 0.7862 - val_loss: 1.3459 - val_accuracy: 0.6509\n",
            "Epoch 25/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6368 - accuracy: 0.7883 - val_loss: 1.3789 - val_accuracy: 0.6499\n",
            "Epoch 26/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6284 - accuracy: 0.7870 - val_loss: 1.6188 - val_accuracy: 0.5996\n",
            "Epoch 27/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6342 - accuracy: 0.7894 - val_loss: 1.4981 - val_accuracy: 0.6190\n",
            "Epoch 28/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6305 - accuracy: 0.7878 - val_loss: 1.5293 - val_accuracy: 0.6166\n",
            "Epoch 29/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6304 - accuracy: 0.7887 - val_loss: 1.3133 - val_accuracy: 0.6555\n",
            "Epoch 30/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6258 - accuracy: 0.7920 - val_loss: 1.7396 - val_accuracy: 0.5778\n",
            "Epoch 31/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.7883 - val_loss: 1.3738 - val_accuracy: 0.6434\n",
            "Epoch 32/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6233 - accuracy: 0.7914 - val_loss: 1.3673 - val_accuracy: 0.6458\n",
            "Epoch 33/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6261 - accuracy: 0.7899 - val_loss: 1.3768 - val_accuracy: 0.6558\n",
            "Epoch 34/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6225 - accuracy: 0.7916 - val_loss: 1.4851 - val_accuracy: 0.6197\n",
            "Epoch 35/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6259 - accuracy: 0.7912 - val_loss: 1.5229 - val_accuracy: 0.6165\n",
            "Epoch 36/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6128 - accuracy: 0.7952 - val_loss: 1.3657 - val_accuracy: 0.6497\n",
            "Epoch 37/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6123 - accuracy: 0.7932 - val_loss: 1.6548 - val_accuracy: 0.6015\n",
            "Epoch 38/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6228 - accuracy: 0.7927 - val_loss: 1.3835 - val_accuracy: 0.6547\n",
            "Epoch 39/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6209 - accuracy: 0.7918 - val_loss: 1.5616 - val_accuracy: 0.6208\n",
            "Epoch 40/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6119 - accuracy: 0.7967 - val_loss: 1.3545 - val_accuracy: 0.6565\n",
            "Epoch 41/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.7944 - val_loss: 1.3364 - val_accuracy: 0.6566\n",
            "Epoch 42/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6190 - accuracy: 0.7916 - val_loss: 1.5464 - val_accuracy: 0.6214\n",
            "Epoch 43/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6249 - accuracy: 0.7916 - val_loss: 1.4912 - val_accuracy: 0.6309\n",
            "Epoch 44/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6096 - accuracy: 0.7946 - val_loss: 1.3742 - val_accuracy: 0.6513\n",
            "Epoch 45/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6164 - accuracy: 0.7933 - val_loss: 1.4752 - val_accuracy: 0.6377\n",
            "Epoch 46/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6078 - accuracy: 0.7962 - val_loss: 1.3270 - val_accuracy: 0.6634\n",
            "Epoch 47/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6193 - accuracy: 0.7936 - val_loss: 1.5277 - val_accuracy: 0.6055\n",
            "Epoch 48/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6033 - accuracy: 0.7973 - val_loss: 1.3246 - val_accuracy: 0.6559\n",
            "Epoch 49/50\n",
            "470/470 [==============================] - 1s 3ms/step - loss: 0.6156 - accuracy: 0.7931 - val_loss: 1.3229 - val_accuracy: 0.6598\n",
            "Epoch 50/50\n",
            "470/470 [==============================] - 2s 3ms/step - loss: 0.6103 - accuracy: 0.7954 - val_loss: 1.6713 - val_accuracy: 0.6005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd35d0800d0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_ZJwCqA-s2r",
        "outputId": "67af9750-5bc5-4713-eea5-873a596bfe7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 1.6937 - accuracy: 0.5903\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.693665623664856, 0.5902796387672424]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nudozzzW-Voi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste com CNN"
      ],
      "metadata": {
        "id": "7ZevRqtbAji6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#model.add(Dense(92, activation='tanh', input_shape=(92,)))\n",
        "model.add(Conv1D(92, kernel_size=(1), activation='relu', input_shape=(1,92)))\n",
        "\n",
        "model.add(Conv1D(92, kernel_size=(1), activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=(1)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEDqQ2tCAlfC",
        "outputId": "eb69104f-9672-4020-dea0-66074414aec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_9 (Conv1D)           (None, 1, 92)             8556      \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 1, 92)             8556      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 1, 92)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 1, 92)             0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 92)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               11904     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,338\n",
            "Trainable params: 31,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_scaled_2d, y_train, batch_size=128, epochs=50, verbose=1, validation_data=(X_valid_scaled_2d, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIer07duHjHB",
        "outputId": "e7d3cc13-6390-4239-f927-ebeb9c43b751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "470/470 [==============================] - 3s 6ms/step - loss: 1.3383 - accuracy: 0.5486 - val_loss: 1.3607 - val_accuracy: 0.5599\n",
            "Epoch 2/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3306 - accuracy: 0.5532 - val_loss: 1.3128 - val_accuracy: 0.5802\n",
            "Epoch 3/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3324 - accuracy: 0.5518 - val_loss: 1.3358 - val_accuracy: 0.5678\n",
            "Epoch 4/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3303 - accuracy: 0.5517 - val_loss: 1.3684 - val_accuracy: 0.5587\n",
            "Epoch 5/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3225 - accuracy: 0.5547 - val_loss: 1.2934 - val_accuracy: 0.5830\n",
            "Epoch 6/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3271 - accuracy: 0.5534 - val_loss: 1.2843 - val_accuracy: 0.5832\n",
            "Epoch 7/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3253 - accuracy: 0.5534 - val_loss: 1.3178 - val_accuracy: 0.5708\n",
            "Epoch 8/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3272 - accuracy: 0.5541 - val_loss: 1.3234 - val_accuracy: 0.5702\n",
            "Epoch 9/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3251 - accuracy: 0.5534 - val_loss: 1.3129 - val_accuracy: 0.5730\n",
            "Epoch 10/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3261 - accuracy: 0.5534 - val_loss: 1.2882 - val_accuracy: 0.5815\n",
            "Epoch 11/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3238 - accuracy: 0.5544 - val_loss: 1.3555 - val_accuracy: 0.5567\n",
            "Epoch 12/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3234 - accuracy: 0.5547 - val_loss: 1.2982 - val_accuracy: 0.5799\n",
            "Epoch 13/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3201 - accuracy: 0.5577 - val_loss: 1.3403 - val_accuracy: 0.5650\n",
            "Epoch 14/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3187 - accuracy: 0.5571 - val_loss: 1.3176 - val_accuracy: 0.5708\n",
            "Epoch 15/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3195 - accuracy: 0.5588 - val_loss: 1.3256 - val_accuracy: 0.5706\n",
            "Epoch 16/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3174 - accuracy: 0.5565 - val_loss: 1.3198 - val_accuracy: 0.5710\n",
            "Epoch 17/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3162 - accuracy: 0.5566 - val_loss: 1.3199 - val_accuracy: 0.5719\n",
            "Epoch 18/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3130 - accuracy: 0.5587 - val_loss: 1.3500 - val_accuracy: 0.5667\n",
            "Epoch 19/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3168 - accuracy: 0.5578 - val_loss: 1.3647 - val_accuracy: 0.5609\n",
            "Epoch 20/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3130 - accuracy: 0.5589 - val_loss: 1.2667 - val_accuracy: 0.5900\n",
            "Epoch 21/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3189 - accuracy: 0.5571 - val_loss: 1.2927 - val_accuracy: 0.5838\n",
            "Epoch 22/50\n",
            "470/470 [==============================] - 3s 6ms/step - loss: 1.3095 - accuracy: 0.5622 - val_loss: 1.3307 - val_accuracy: 0.5652\n",
            "Epoch 23/50\n",
            "470/470 [==============================] - 3s 6ms/step - loss: 1.3065 - accuracy: 0.5635 - val_loss: 1.2611 - val_accuracy: 0.5939\n",
            "Epoch 24/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3111 - accuracy: 0.5599 - val_loss: 1.3217 - val_accuracy: 0.5722\n",
            "Epoch 25/50\n",
            "470/470 [==============================] - 3s 5ms/step - loss: 1.3069 - accuracy: 0.5634 - val_loss: 1.3331 - val_accuracy: 0.5702\n",
            "Epoch 26/50\n",
            "470/470 [==============================] - 3s 6ms/step - loss: 1.3082 - accuracy: 0.5602 - val_loss: 1.3272 - val_accuracy: 0.5780\n",
            "Epoch 27/50\n",
            "470/470 [==============================] - 3s 5ms/step - loss: 1.3067 - accuracy: 0.5613 - val_loss: 1.3102 - val_accuracy: 0.5780\n",
            "Epoch 28/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3049 - accuracy: 0.5601 - val_loss: 1.2907 - val_accuracy: 0.5787\n",
            "Epoch 29/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3032 - accuracy: 0.5612 - val_loss: 1.3040 - val_accuracy: 0.5791\n",
            "Epoch 30/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2994 - accuracy: 0.5638 - val_loss: 1.3011 - val_accuracy: 0.5784\n",
            "Epoch 31/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3044 - accuracy: 0.5615 - val_loss: 1.2843 - val_accuracy: 0.5851\n",
            "Epoch 32/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3043 - accuracy: 0.5629 - val_loss: 1.2799 - val_accuracy: 0.5908\n",
            "Epoch 33/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2964 - accuracy: 0.5642 - val_loss: 1.3108 - val_accuracy: 0.5731\n",
            "Epoch 34/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2991 - accuracy: 0.5644 - val_loss: 1.2576 - val_accuracy: 0.5996\n",
            "Epoch 35/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.3041 - accuracy: 0.5615 - val_loss: 1.3382 - val_accuracy: 0.5702\n",
            "Epoch 36/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2983 - accuracy: 0.5634 - val_loss: 1.2966 - val_accuracy: 0.5752\n",
            "Epoch 37/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2931 - accuracy: 0.5655 - val_loss: 1.3044 - val_accuracy: 0.5806\n",
            "Epoch 38/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2950 - accuracy: 0.5651 - val_loss: 1.3229 - val_accuracy: 0.5768\n",
            "Epoch 39/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2973 - accuracy: 0.5643 - val_loss: 1.3030 - val_accuracy: 0.5822\n",
            "Epoch 40/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2953 - accuracy: 0.5653 - val_loss: 1.2840 - val_accuracy: 0.5866\n",
            "Epoch 41/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2958 - accuracy: 0.5648 - val_loss: 1.3190 - val_accuracy: 0.5736\n",
            "Epoch 42/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2890 - accuracy: 0.5636 - val_loss: 1.3124 - val_accuracy: 0.5747\n",
            "Epoch 43/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2918 - accuracy: 0.5662 - val_loss: 1.2806 - val_accuracy: 0.5831\n",
            "Epoch 44/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2889 - accuracy: 0.5661 - val_loss: 1.3631 - val_accuracy: 0.5573\n",
            "Epoch 45/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2886 - accuracy: 0.5678 - val_loss: 1.3027 - val_accuracy: 0.5818\n",
            "Epoch 46/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2884 - accuracy: 0.5662 - val_loss: 1.2759 - val_accuracy: 0.5815\n",
            "Epoch 47/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2970 - accuracy: 0.5665 - val_loss: 1.3148 - val_accuracy: 0.5706\n",
            "Epoch 48/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2879 - accuracy: 0.5669 - val_loss: 1.2997 - val_accuracy: 0.5808\n",
            "Epoch 49/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2892 - accuracy: 0.5669 - val_loss: 1.2774 - val_accuracy: 0.5892\n",
            "Epoch 50/50\n",
            "470/470 [==============================] - 2s 5ms/step - loss: 1.2796 - accuracy: 0.5704 - val_loss: 1.2703 - val_accuracy: 0.5892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd35f93a790>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled_2d, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b1x0jDUHm_I",
        "outputId": "7d5d0068-be7f-41b3-9c58-466eee370814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 11ms/step - loss: 2.8888 - accuracy: 0.0602\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.888791084289551, 0.060186419636011124]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E com pca"
      ],
      "metadata": {
        "id": "FTPerOPIaJbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#model.add(Dense(92, activation='tanh', input_shape=(92,)))\n",
        "model.add(Conv1D(30, kernel_size=(1), activation='relu', input_shape=(1,30)))\n",
        "\n",
        "model.add(Conv1D(30, kernel_size=(1), activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=(1)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaTraTXuaK2w",
        "outputId": "79c9cc45-fbe9-45f3-d915-500723c63d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_11 (Conv1D)          (None, 1, 30)             930       \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 1, 30)             930       \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 1, 30)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 1, 30)             0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               3968      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 18)                2322      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,150\n",
            "Trainable params: 8,150\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train_scaled_pca_2d, y_train, batch_size=128, epochs=50, verbose=1, validation_data=(X_valid_scaled_pca_2d, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTFCBN7HaT9h",
        "outputId": "b88d0e46-e6ee-4d9f-f7e9-4a48df71d360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "470/470 [==============================] - 3s 4ms/step - loss: 2.5057 - accuracy: 0.1492 - val_loss: 2.2205 - val_accuracy: 0.2284\n",
            "Epoch 2/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 2.2279 - accuracy: 0.2234 - val_loss: 2.0991 - val_accuracy: 0.2819\n",
            "Epoch 3/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 2.1373 - accuracy: 0.2527 - val_loss: 2.0308 - val_accuracy: 0.3069\n",
            "Epoch 4/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 2.0821 - accuracy: 0.2767 - val_loss: 1.9729 - val_accuracy: 0.3273\n",
            "Epoch 5/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 2.0398 - accuracy: 0.2912 - val_loss: 1.9399 - val_accuracy: 0.3395\n",
            "Epoch 6/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 2.0094 - accuracy: 0.3039 - val_loss: 1.9168 - val_accuracy: 0.3595\n",
            "Epoch 7/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9834 - accuracy: 0.3174 - val_loss: 1.8817 - val_accuracy: 0.3736\n",
            "Epoch 8/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9669 - accuracy: 0.3229 - val_loss: 1.8578 - val_accuracy: 0.3832\n",
            "Epoch 9/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9456 - accuracy: 0.3297 - val_loss: 1.8474 - val_accuracy: 0.3806\n",
            "Epoch 10/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9268 - accuracy: 0.3369 - val_loss: 1.8195 - val_accuracy: 0.3920\n",
            "Epoch 11/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9155 - accuracy: 0.3437 - val_loss: 1.8188 - val_accuracy: 0.3905\n",
            "Epoch 12/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.9001 - accuracy: 0.3484 - val_loss: 1.8051 - val_accuracy: 0.3893\n",
            "Epoch 13/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8904 - accuracy: 0.3507 - val_loss: 1.7967 - val_accuracy: 0.3959\n",
            "Epoch 14/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8830 - accuracy: 0.3540 - val_loss: 1.7812 - val_accuracy: 0.4007\n",
            "Epoch 15/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8722 - accuracy: 0.3592 - val_loss: 1.7794 - val_accuracy: 0.3997\n",
            "Epoch 16/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8654 - accuracy: 0.3631 - val_loss: 1.7613 - val_accuracy: 0.4117\n",
            "Epoch 17/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8550 - accuracy: 0.3637 - val_loss: 1.7730 - val_accuracy: 0.4084\n",
            "Epoch 18/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8508 - accuracy: 0.3663 - val_loss: 1.7493 - val_accuracy: 0.4160\n",
            "Epoch 19/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8448 - accuracy: 0.3694 - val_loss: 1.7424 - val_accuracy: 0.4188\n",
            "Epoch 20/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8367 - accuracy: 0.3736 - val_loss: 1.7375 - val_accuracy: 0.4173\n",
            "Epoch 21/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8324 - accuracy: 0.3749 - val_loss: 1.7341 - val_accuracy: 0.4222\n",
            "Epoch 22/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8269 - accuracy: 0.3763 - val_loss: 1.7412 - val_accuracy: 0.4308\n",
            "Epoch 23/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8206 - accuracy: 0.3792 - val_loss: 1.7208 - val_accuracy: 0.4317\n",
            "Epoch 24/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8171 - accuracy: 0.3806 - val_loss: 1.7247 - val_accuracy: 0.4265\n",
            "Epoch 25/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8122 - accuracy: 0.3802 - val_loss: 1.7221 - val_accuracy: 0.4290\n",
            "Epoch 26/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8094 - accuracy: 0.3827 - val_loss: 1.7301 - val_accuracy: 0.4294\n",
            "Epoch 27/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8011 - accuracy: 0.3869 - val_loss: 1.7214 - val_accuracy: 0.4249\n",
            "Epoch 28/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.8010 - accuracy: 0.3854 - val_loss: 1.7111 - val_accuracy: 0.4314\n",
            "Epoch 29/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7971 - accuracy: 0.3888 - val_loss: 1.7136 - val_accuracy: 0.4340\n",
            "Epoch 30/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7936 - accuracy: 0.3899 - val_loss: 1.7016 - val_accuracy: 0.4366\n",
            "Epoch 31/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7936 - accuracy: 0.3883 - val_loss: 1.7137 - val_accuracy: 0.4332\n",
            "Epoch 32/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7926 - accuracy: 0.3886 - val_loss: 1.7137 - val_accuracy: 0.4334\n",
            "Epoch 33/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7806 - accuracy: 0.3922 - val_loss: 1.6980 - val_accuracy: 0.4360\n",
            "Epoch 34/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7856 - accuracy: 0.3906 - val_loss: 1.7172 - val_accuracy: 0.4289\n",
            "Epoch 35/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7812 - accuracy: 0.3930 - val_loss: 1.6929 - val_accuracy: 0.4389\n",
            "Epoch 36/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7775 - accuracy: 0.3918 - val_loss: 1.6914 - val_accuracy: 0.4348\n",
            "Epoch 37/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7789 - accuracy: 0.3935 - val_loss: 1.6998 - val_accuracy: 0.4373\n",
            "Epoch 38/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7742 - accuracy: 0.3973 - val_loss: 1.6827 - val_accuracy: 0.4401\n",
            "Epoch 39/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7712 - accuracy: 0.3989 - val_loss: 1.6860 - val_accuracy: 0.4430\n",
            "Epoch 40/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7655 - accuracy: 0.3981 - val_loss: 1.6917 - val_accuracy: 0.4358\n",
            "Epoch 41/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7677 - accuracy: 0.3977 - val_loss: 1.6839 - val_accuracy: 0.4401\n",
            "Epoch 42/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7683 - accuracy: 0.3973 - val_loss: 1.6877 - val_accuracy: 0.4419\n",
            "Epoch 43/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7608 - accuracy: 0.4009 - val_loss: 1.6909 - val_accuracy: 0.4377\n",
            "Epoch 44/50\n",
            "470/470 [==============================] - 3s 6ms/step - loss: 1.7623 - accuracy: 0.4008 - val_loss: 1.6850 - val_accuracy: 0.4410\n",
            "Epoch 45/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7593 - accuracy: 0.4021 - val_loss: 1.6575 - val_accuracy: 0.4466\n",
            "Epoch 46/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7589 - accuracy: 0.4019 - val_loss: 1.6800 - val_accuracy: 0.4421\n",
            "Epoch 47/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7557 - accuracy: 0.4030 - val_loss: 1.6821 - val_accuracy: 0.4405\n",
            "Epoch 48/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7560 - accuracy: 0.4004 - val_loss: 1.6561 - val_accuracy: 0.4486\n",
            "Epoch 49/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7522 - accuracy: 0.4031 - val_loss: 1.6864 - val_accuracy: 0.4386\n",
            "Epoch 50/50\n",
            "470/470 [==============================] - 2s 4ms/step - loss: 1.7502 - accuracy: 0.4048 - val_loss: 1.6682 - val_accuracy: 0.4410\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd35211c290>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled_pca_2d, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUYTcOXnadCD",
        "outputId": "3eaa5cbb-0b03-43cd-b299-ec7cdd49e2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 1.6297 - accuracy: 0.4479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6297285556793213, 0.447936087846756]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GLEGzMBgaS5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Bidirecional"
      ],
      "metadata": {
        "id": "wP0hYhNUyXke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(92, return_sequences=True),input_shape=(1,92)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Bidirectional(LSTM(92,return_sequences=True,dropout=0.5, recurrent_dropout=0.5,activation='relu')))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSY-zJTxyMnV",
        "outputId": "3b2114b2-9ebb-4658-f48d-229fb35ca736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 1, 184)           136160    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 1, 184)           736       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 1, 184)           203872    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 1, 184)           736       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 184)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 18)                3330      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 344,834\n",
            "Trainable params: 344,098\n",
            "Non-trainable params: 736\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model.fit(X_train_scaled_2d, y_train, batch_size=201, epochs=100, verbose=1, validation_data=(X_valid_scaled_2d, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW45JrFmy4wx",
        "outputId": "cf221135-720e-4bad-9fea-a7b6761d2b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "299/299 [==============================] - 21s 39ms/step - loss: 2.2330 - accuracy: 0.2771 - val_loss: 2.6849 - val_accuracy: 0.1099\n",
            "Epoch 2/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.8460 - accuracy: 0.3886 - val_loss: 1.8642 - val_accuracy: 0.3848\n",
            "Epoch 3/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.7007 - accuracy: 0.4342 - val_loss: 1.7831 - val_accuracy: 0.4220\n",
            "Epoch 4/100\n",
            "299/299 [==============================] - 11s 37ms/step - loss: 1.6150 - accuracy: 0.4625 - val_loss: 1.7516 - val_accuracy: 0.4358\n",
            "Epoch 5/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.5524 - accuracy: 0.4834 - val_loss: 1.7458 - val_accuracy: 0.4334\n",
            "Epoch 6/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.5022 - accuracy: 0.4986 - val_loss: 1.9145 - val_accuracy: 0.3993\n",
            "Epoch 7/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.4606 - accuracy: 0.5106 - val_loss: 1.7068 - val_accuracy: 0.4483\n",
            "Epoch 8/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.4334 - accuracy: 0.5196 - val_loss: 1.6993 - val_accuracy: 0.4581\n",
            "Epoch 9/100\n",
            "299/299 [==============================] - 11s 36ms/step - loss: 1.4010 - accuracy: 0.5312 - val_loss: 1.6377 - val_accuracy: 0.4533\n",
            "Epoch 10/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 1.3803 - accuracy: 0.5381 - val_loss: 1.7274 - val_accuracy: 0.4628\n",
            "Epoch 11/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 1.3541 - accuracy: 0.5477 - val_loss: 1.6115 - val_accuracy: 0.4904\n",
            "Epoch 12/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.3347 - accuracy: 0.5543 - val_loss: 1.6815 - val_accuracy: 0.4628\n",
            "Epoch 13/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.3110 - accuracy: 0.5591 - val_loss: 1.4888 - val_accuracy: 0.4947\n",
            "Epoch 14/100\n",
            "299/299 [==============================] - 12s 40ms/step - loss: 1.2966 - accuracy: 0.5659 - val_loss: 1.4556 - val_accuracy: 0.5146\n",
            "Epoch 15/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 1.2800 - accuracy: 0.5717 - val_loss: 1.4387 - val_accuracy: 0.5272\n",
            "Epoch 16/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 1.2686 - accuracy: 0.5768 - val_loss: 1.4055 - val_accuracy: 0.5442\n",
            "Epoch 17/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 1.2575 - accuracy: 0.5801 - val_loss: 1.4279 - val_accuracy: 0.5222\n",
            "Epoch 18/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 1.2444 - accuracy: 0.5829 - val_loss: 1.6100 - val_accuracy: 0.5194\n",
            "Epoch 19/100\n",
            "299/299 [==============================] - 11s 37ms/step - loss: 1.2308 - accuracy: 0.5902 - val_loss: 1.5524 - val_accuracy: 0.5079\n",
            "Epoch 20/100\n",
            "299/299 [==============================] - 11s 36ms/step - loss: 1.2198 - accuracy: 0.5921 - val_loss: 1.4043 - val_accuracy: 0.5423\n",
            "Epoch 21/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.2113 - accuracy: 0.5937 - val_loss: 1.5174 - val_accuracy: 0.5164\n",
            "Epoch 22/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.2104 - accuracy: 0.5951 - val_loss: 1.5623 - val_accuracy: 0.5039\n",
            "Epoch 23/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1911 - accuracy: 0.6033 - val_loss: 1.3845 - val_accuracy: 0.5441\n",
            "Epoch 24/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1876 - accuracy: 0.6029 - val_loss: 1.5620 - val_accuracy: 0.4965\n",
            "Epoch 25/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1841 - accuracy: 0.6061 - val_loss: 1.3660 - val_accuracy: 0.5541\n",
            "Epoch 26/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1746 - accuracy: 0.6075 - val_loss: 1.4668 - val_accuracy: 0.5206\n",
            "Epoch 27/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1617 - accuracy: 0.6087 - val_loss: 1.3460 - val_accuracy: 0.5675\n",
            "Epoch 28/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1560 - accuracy: 0.6130 - val_loss: 1.3456 - val_accuracy: 0.5795\n",
            "Epoch 29/100\n",
            "299/299 [==============================] - 10s 32ms/step - loss: 1.1529 - accuracy: 0.6152 - val_loss: 1.2270 - val_accuracy: 0.5908\n",
            "Epoch 30/100\n",
            "299/299 [==============================] - 10s 32ms/step - loss: 1.1476 - accuracy: 0.6155 - val_loss: 1.6103 - val_accuracy: 0.5128\n",
            "Epoch 31/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1412 - accuracy: 0.6195 - val_loss: 1.4314 - val_accuracy: 0.5398\n",
            "Epoch 32/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1363 - accuracy: 0.6211 - val_loss: 1.2427 - val_accuracy: 0.5964\n",
            "Epoch 33/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1272 - accuracy: 0.6229 - val_loss: 1.5234 - val_accuracy: 0.5337\n",
            "Epoch 34/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1204 - accuracy: 0.6258 - val_loss: 1.4173 - val_accuracy: 0.5562\n",
            "Epoch 35/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1170 - accuracy: 0.6271 - val_loss: 1.3461 - val_accuracy: 0.5609\n",
            "Epoch 36/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1103 - accuracy: 0.6299 - val_loss: 1.2576 - val_accuracy: 0.5874\n",
            "Epoch 37/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1075 - accuracy: 0.6306 - val_loss: 1.3924 - val_accuracy: 0.5475\n",
            "Epoch 38/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1007 - accuracy: 0.6328 - val_loss: 1.4485 - val_accuracy: 0.5348\n",
            "Epoch 39/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.1062 - accuracy: 0.6286 - val_loss: 1.4229 - val_accuracy: 0.5431\n",
            "Epoch 40/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0919 - accuracy: 0.6343 - val_loss: 1.2958 - val_accuracy: 0.5736\n",
            "Epoch 41/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0895 - accuracy: 0.6352 - val_loss: 1.4992 - val_accuracy: 0.5290\n",
            "Epoch 42/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0868 - accuracy: 0.6382 - val_loss: 1.5336 - val_accuracy: 0.5226\n",
            "Epoch 43/100\n",
            "299/299 [==============================] - 12s 41ms/step - loss: 1.0791 - accuracy: 0.6371 - val_loss: 1.2175 - val_accuracy: 0.6055\n",
            "Epoch 44/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0773 - accuracy: 0.6385 - val_loss: 1.2217 - val_accuracy: 0.5943\n",
            "Epoch 45/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0715 - accuracy: 0.6410 - val_loss: 1.4434 - val_accuracy: 0.5406\n",
            "Epoch 46/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0681 - accuracy: 0.6419 - val_loss: 1.3879 - val_accuracy: 0.5674\n",
            "Epoch 47/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0661 - accuracy: 0.6440 - val_loss: 1.2210 - val_accuracy: 0.6051\n",
            "Epoch 48/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0602 - accuracy: 0.6447 - val_loss: 1.4153 - val_accuracy: 0.5465\n",
            "Epoch 49/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0572 - accuracy: 0.6473 - val_loss: 1.2680 - val_accuracy: 0.5903\n",
            "Epoch 50/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0556 - accuracy: 0.6465 - val_loss: 1.4439 - val_accuracy: 0.5530\n",
            "Epoch 51/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0558 - accuracy: 0.6477 - val_loss: 1.2418 - val_accuracy: 0.5953\n",
            "Epoch 52/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0499 - accuracy: 0.6479 - val_loss: 1.5080 - val_accuracy: 0.5382\n",
            "Epoch 53/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0455 - accuracy: 0.6489 - val_loss: 1.2776 - val_accuracy: 0.5940\n",
            "Epoch 54/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0426 - accuracy: 0.6501 - val_loss: 1.4711 - val_accuracy: 0.5374\n",
            "Epoch 55/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0430 - accuracy: 0.6501 - val_loss: 1.3261 - val_accuracy: 0.5734\n",
            "Epoch 56/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0433 - accuracy: 0.6541 - val_loss: 1.4058 - val_accuracy: 0.5505\n",
            "Epoch 57/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0397 - accuracy: 0.6508 - val_loss: 1.3196 - val_accuracy: 0.5798\n",
            "Epoch 58/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0358 - accuracy: 0.6535 - val_loss: 1.3636 - val_accuracy: 0.5687\n",
            "Epoch 59/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0264 - accuracy: 0.6580 - val_loss: 1.2197 - val_accuracy: 0.6005\n",
            "Epoch 60/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0303 - accuracy: 0.6582 - val_loss: 1.3955 - val_accuracy: 0.5511\n",
            "Epoch 61/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0290 - accuracy: 0.6566 - val_loss: 1.3781 - val_accuracy: 0.5751\n",
            "Epoch 62/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0186 - accuracy: 0.6604 - val_loss: 1.2239 - val_accuracy: 0.6029\n",
            "Epoch 63/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0186 - accuracy: 0.6598 - val_loss: 1.2777 - val_accuracy: 0.5879\n",
            "Epoch 64/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0169 - accuracy: 0.6612 - val_loss: 1.3693 - val_accuracy: 0.5744\n",
            "Epoch 65/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0141 - accuracy: 0.6611 - val_loss: 1.4021 - val_accuracy: 0.5613\n",
            "Epoch 66/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0084 - accuracy: 0.6637 - val_loss: 1.4512 - val_accuracy: 0.5565\n",
            "Epoch 67/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0061 - accuracy: 0.6648 - val_loss: 1.3206 - val_accuracy: 0.5866\n",
            "Epoch 68/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0089 - accuracy: 0.6615 - val_loss: 1.4090 - val_accuracy: 0.5682\n",
            "Epoch 69/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0000 - accuracy: 0.6658 - val_loss: 1.2587 - val_accuracy: 0.5916\n",
            "Epoch 70/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0044 - accuracy: 0.6629 - val_loss: 1.1684 - val_accuracy: 0.6246\n",
            "Epoch 71/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0046 - accuracy: 0.6630 - val_loss: 1.2983 - val_accuracy: 0.5928\n",
            "Epoch 72/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 1.0007 - accuracy: 0.6638 - val_loss: 1.3398 - val_accuracy: 0.5846\n",
            "Epoch 73/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9993 - accuracy: 0.6666 - val_loss: 1.3904 - val_accuracy: 0.5672\n",
            "Epoch 74/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9914 - accuracy: 0.6683 - val_loss: 1.2335 - val_accuracy: 0.5999\n",
            "Epoch 75/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9882 - accuracy: 0.6718 - val_loss: 1.2243 - val_accuracy: 0.6152\n",
            "Epoch 76/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9944 - accuracy: 0.6668 - val_loss: 1.3410 - val_accuracy: 0.5852\n",
            "Epoch 77/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9904 - accuracy: 0.6695 - val_loss: 1.2160 - val_accuracy: 0.6141\n",
            "Epoch 78/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9857 - accuracy: 0.6701 - val_loss: 1.1968 - val_accuracy: 0.6194\n",
            "Epoch 79/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9886 - accuracy: 0.6698 - val_loss: 1.1609 - val_accuracy: 0.6314\n",
            "Epoch 80/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9820 - accuracy: 0.6722 - val_loss: 1.1668 - val_accuracy: 0.6230\n",
            "Epoch 81/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9761 - accuracy: 0.6741 - val_loss: 1.1492 - val_accuracy: 0.6310\n",
            "Epoch 82/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9765 - accuracy: 0.6738 - val_loss: 1.3069 - val_accuracy: 0.5897\n",
            "Epoch 83/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9802 - accuracy: 0.6714 - val_loss: 1.2138 - val_accuracy: 0.6144\n",
            "Epoch 84/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9776 - accuracy: 0.6725 - val_loss: 1.2248 - val_accuracy: 0.6111\n",
            "Epoch 85/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9755 - accuracy: 0.6739 - val_loss: 1.2420 - val_accuracy: 0.6072\n",
            "Epoch 86/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9714 - accuracy: 0.6743 - val_loss: 1.2311 - val_accuracy: 0.6093\n",
            "Epoch 87/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9688 - accuracy: 0.6754 - val_loss: 1.2703 - val_accuracy: 0.5985\n",
            "Epoch 88/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9725 - accuracy: 0.6750 - val_loss: 1.2279 - val_accuracy: 0.6278\n",
            "Epoch 89/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9688 - accuracy: 0.6752 - val_loss: 1.2677 - val_accuracy: 0.6071\n",
            "Epoch 90/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9653 - accuracy: 0.6801 - val_loss: 1.2205 - val_accuracy: 0.6189\n",
            "Epoch 91/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9636 - accuracy: 0.6768 - val_loss: 1.2281 - val_accuracy: 0.6128\n",
            "Epoch 92/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9595 - accuracy: 0.6794 - val_loss: 1.2157 - val_accuracy: 0.6160\n",
            "Epoch 93/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9600 - accuracy: 0.6794 - val_loss: 1.3620 - val_accuracy: 0.5864\n",
            "Epoch 94/100\n",
            "299/299 [==============================] - 10s 33ms/step - loss: 0.9571 - accuracy: 0.6793 - val_loss: 1.2167 - val_accuracy: 0.6165\n",
            "Epoch 95/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9597 - accuracy: 0.6776 - val_loss: 1.2174 - val_accuracy: 0.6037\n",
            "Epoch 96/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9543 - accuracy: 0.6800 - val_loss: 1.1048 - val_accuracy: 0.6467\n",
            "Epoch 97/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9510 - accuracy: 0.6839 - val_loss: 1.2275 - val_accuracy: 0.6194\n",
            "Epoch 98/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9461 - accuracy: 0.6839 - val_loss: 1.3543 - val_accuracy: 0.5844\n",
            "Epoch 99/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9522 - accuracy: 0.6848 - val_loss: 1.1601 - val_accuracy: 0.6204\n",
            "Epoch 100/100\n",
            "299/299 [==============================] - 10s 34ms/step - loss: 0.9460 - accuracy: 0.6838 - val_loss: 1.2648 - val_accuracy: 0.6040\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd359ca8150>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled_2d, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xiKhmsnzHK3",
        "outputId": "317e1cf4-a143-4216-b939-dffc945f767a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 15ms/step - loss: 1.1602 - accuracy: 0.6441\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1602237224578857, 0.644074559211731]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN+LSTM"
      ],
      "metadata": {
        "id": "oqe3uRvyfTeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#model.add(Dense(92, activation='tanh', input_shape=(92,)))\n",
        "model.add(Conv1D(92, kernel_size=(1), activation='relu', input_shape=(1,92)))\n",
        "model.add(MaxPooling1D(pool_size=(1)))\n",
        "model.add(Conv1D(92, kernel_size=(1), activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=(1)))\n",
        "model.add(LSTM(184))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "#model.add(LSTM(92))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(184, activation='tanh'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXggQjcLfVaH",
        "outputId": "b0659caa-b50c-47d6-d841-912c51096467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_15 (Conv1D)          (None, 1, 92)             8556      \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 1, 92)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, 1, 92)             8556      \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 1, 92)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 184)               203872    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 184)              736       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 184)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 184)               34040     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 184)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 18)                3330      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 259,090\n",
            "Trainable params: 258,722\n",
            "Non-trainable params: 368\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(\n",
        "    X_train_scaled_2d,\n",
        "    y_train,\n",
        "    batch_size=128,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=(X_valid_scaled_2d, y_valid)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPgVdILBfcBv",
        "outputId": "c608404b-cfe8-4ac0-edde-5cf9a117126c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "470/470 [==============================] - 10s 16ms/step - loss: 2.1773 - accuracy: 0.2703 - val_loss: 2.4212 - val_accuracy: 0.2518\n",
            "Epoch 2/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.8764 - accuracy: 0.3743 - val_loss: 1.8104 - val_accuracy: 0.3908\n",
            "Epoch 3/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.7410 - accuracy: 0.4199 - val_loss: 1.7155 - val_accuracy: 0.4212\n",
            "Epoch 4/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.6673 - accuracy: 0.4433 - val_loss: 1.6897 - val_accuracy: 0.4417\n",
            "Epoch 5/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.6086 - accuracy: 0.4638 - val_loss: 1.7347 - val_accuracy: 0.4306\n",
            "Epoch 6/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.5659 - accuracy: 0.4772 - val_loss: 1.6433 - val_accuracy: 0.4534\n",
            "Epoch 7/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 1.5269 - accuracy: 0.4941 - val_loss: 1.6004 - val_accuracy: 0.4660\n",
            "Epoch 8/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.4923 - accuracy: 0.5072 - val_loss: 1.6808 - val_accuracy: 0.4578\n",
            "Epoch 9/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.4677 - accuracy: 0.5145 - val_loss: 1.6605 - val_accuracy: 0.4755\n",
            "Epoch 10/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.4424 - accuracy: 0.5245 - val_loss: 1.5467 - val_accuracy: 0.4973\n",
            "Epoch 11/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.4185 - accuracy: 0.5294 - val_loss: 1.5604 - val_accuracy: 0.4883\n",
            "Epoch 12/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.3965 - accuracy: 0.5374 - val_loss: 1.5361 - val_accuracy: 0.4879\n",
            "Epoch 13/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.3718 - accuracy: 0.5477 - val_loss: 1.5760 - val_accuracy: 0.4879\n",
            "Epoch 14/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.3480 - accuracy: 0.5551 - val_loss: 1.4477 - val_accuracy: 0.5198\n",
            "Epoch 15/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.3257 - accuracy: 0.5610 - val_loss: 1.6439 - val_accuracy: 0.4679\n",
            "Epoch 16/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.3060 - accuracy: 0.5686 - val_loss: 1.4616 - val_accuracy: 0.5075\n",
            "Epoch 17/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.2864 - accuracy: 0.5757 - val_loss: 1.5019 - val_accuracy: 0.5083\n",
            "Epoch 18/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.2673 - accuracy: 0.5804 - val_loss: 1.4246 - val_accuracy: 0.5386\n",
            "Epoch 19/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.2482 - accuracy: 0.5879 - val_loss: 1.6287 - val_accuracy: 0.4772\n",
            "Epoch 20/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.2269 - accuracy: 0.5949 - val_loss: 1.4407 - val_accuracy: 0.5288\n",
            "Epoch 21/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.2147 - accuracy: 0.5989 - val_loss: 1.5267 - val_accuracy: 0.5065\n",
            "Epoch 22/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.1884 - accuracy: 0.6101 - val_loss: 1.4988 - val_accuracy: 0.5232\n",
            "Epoch 23/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.1781 - accuracy: 0.6123 - val_loss: 1.4433 - val_accuracy: 0.5421\n",
            "Epoch 24/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.1571 - accuracy: 0.6198 - val_loss: 1.3885 - val_accuracy: 0.5530\n",
            "Epoch 25/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.1423 - accuracy: 0.6232 - val_loss: 1.4104 - val_accuracy: 0.5474\n",
            "Epoch 26/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.1275 - accuracy: 0.6289 - val_loss: 1.2843 - val_accuracy: 0.5814\n",
            "Epoch 27/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.1150 - accuracy: 0.6329 - val_loss: 1.4402 - val_accuracy: 0.5418\n",
            "Epoch 28/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0988 - accuracy: 0.6383 - val_loss: 1.4118 - val_accuracy: 0.5482\n",
            "Epoch 29/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0828 - accuracy: 0.6438 - val_loss: 1.3796 - val_accuracy: 0.5553\n",
            "Epoch 30/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0723 - accuracy: 0.6471 - val_loss: 1.3912 - val_accuracy: 0.5611\n",
            "Epoch 31/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0567 - accuracy: 0.6504 - val_loss: 1.3774 - val_accuracy: 0.5466\n",
            "Epoch 32/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0513 - accuracy: 0.6544 - val_loss: 1.4217 - val_accuracy: 0.5559\n",
            "Epoch 33/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0285 - accuracy: 0.6611 - val_loss: 1.4286 - val_accuracy: 0.5453\n",
            "Epoch 34/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 1.0200 - accuracy: 0.6655 - val_loss: 1.3598 - val_accuracy: 0.5639\n",
            "Epoch 35/100\n",
            "470/470 [==============================] - 8s 16ms/step - loss: 1.0109 - accuracy: 0.6648 - val_loss: 1.3040 - val_accuracy: 0.5819\n",
            "Epoch 36/100\n",
            "470/470 [==============================] - 8s 16ms/step - loss: 0.9938 - accuracy: 0.6721 - val_loss: 1.2993 - val_accuracy: 0.5903\n",
            "Epoch 37/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.9874 - accuracy: 0.6745 - val_loss: 1.2794 - val_accuracy: 0.5945\n",
            "Epoch 38/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.9719 - accuracy: 0.6815 - val_loss: 1.3430 - val_accuracy: 0.5750\n",
            "Epoch 39/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.9623 - accuracy: 0.6819 - val_loss: 1.2958 - val_accuracy: 0.5927\n",
            "Epoch 40/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.9492 - accuracy: 0.6875 - val_loss: 1.4691 - val_accuracy: 0.5628\n",
            "Epoch 41/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.9427 - accuracy: 0.6915 - val_loss: 1.3746 - val_accuracy: 0.5699\n",
            "Epoch 42/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.9331 - accuracy: 0.6923 - val_loss: 1.2692 - val_accuracy: 0.6095\n",
            "Epoch 43/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.9249 - accuracy: 0.6954 - val_loss: 1.4068 - val_accuracy: 0.5676\n",
            "Epoch 44/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.9163 - accuracy: 0.6980 - val_loss: 1.3406 - val_accuracy: 0.5862\n",
            "Epoch 45/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8988 - accuracy: 0.7028 - val_loss: 1.2270 - val_accuracy: 0.6224\n",
            "Epoch 46/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8914 - accuracy: 0.7069 - val_loss: 1.2911 - val_accuracy: 0.6024\n",
            "Epoch 47/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8883 - accuracy: 0.7082 - val_loss: 1.2779 - val_accuracy: 0.6075\n",
            "Epoch 48/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8726 - accuracy: 0.7119 - val_loss: 1.3906 - val_accuracy: 0.5786\n",
            "Epoch 49/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8701 - accuracy: 0.7140 - val_loss: 1.3062 - val_accuracy: 0.5919\n",
            "Epoch 50/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8584 - accuracy: 0.7182 - val_loss: 1.2593 - val_accuracy: 0.6079\n",
            "Epoch 51/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8600 - accuracy: 0.7182 - val_loss: 1.1976 - val_accuracy: 0.6290\n",
            "Epoch 52/100\n",
            "470/470 [==============================] - 8s 16ms/step - loss: 0.8428 - accuracy: 0.7213 - val_loss: 1.2118 - val_accuracy: 0.6246\n",
            "Epoch 53/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.8393 - accuracy: 0.7259 - val_loss: 1.3541 - val_accuracy: 0.5828\n",
            "Epoch 54/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.8321 - accuracy: 0.7260 - val_loss: 1.2756 - val_accuracy: 0.6041\n",
            "Epoch 55/100\n",
            "470/470 [==============================] - 8s 16ms/step - loss: 0.8247 - accuracy: 0.7307 - val_loss: 1.3538 - val_accuracy: 0.5899\n",
            "Epoch 56/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.8194 - accuracy: 0.7322 - val_loss: 1.4038 - val_accuracy: 0.5778\n",
            "Epoch 57/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.8133 - accuracy: 0.7315 - val_loss: 1.3090 - val_accuracy: 0.6059\n",
            "Epoch 58/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.8056 - accuracy: 0.7354 - val_loss: 1.2823 - val_accuracy: 0.6169\n",
            "Epoch 59/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.7979 - accuracy: 0.7356 - val_loss: 1.3160 - val_accuracy: 0.6017\n",
            "Epoch 60/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7940 - accuracy: 0.7398 - val_loss: 1.3171 - val_accuracy: 0.6076\n",
            "Epoch 61/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.7833 - accuracy: 0.7418 - val_loss: 1.2635 - val_accuracy: 0.6158\n",
            "Epoch 62/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7771 - accuracy: 0.7446 - val_loss: 1.3309 - val_accuracy: 0.6015\n",
            "Epoch 63/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7676 - accuracy: 0.7466 - val_loss: 1.2658 - val_accuracy: 0.6198\n",
            "Epoch 64/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7669 - accuracy: 0.7480 - val_loss: 1.3403 - val_accuracy: 0.5952\n",
            "Epoch 65/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7608 - accuracy: 0.7499 - val_loss: 1.2171 - val_accuracy: 0.6354\n",
            "Epoch 66/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7540 - accuracy: 0.7528 - val_loss: 1.3446 - val_accuracy: 0.6015\n",
            "Epoch 67/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7512 - accuracy: 0.7524 - val_loss: 1.2812 - val_accuracy: 0.6174\n",
            "Epoch 68/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7445 - accuracy: 0.7541 - val_loss: 1.5144 - val_accuracy: 0.5706\n",
            "Epoch 69/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7342 - accuracy: 0.7581 - val_loss: 1.2553 - val_accuracy: 0.6245\n",
            "Epoch 70/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7375 - accuracy: 0.7573 - val_loss: 1.2701 - val_accuracy: 0.6256\n",
            "Epoch 71/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7327 - accuracy: 0.7587 - val_loss: 1.2514 - val_accuracy: 0.6237\n",
            "Epoch 72/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7286 - accuracy: 0.7597 - val_loss: 1.1316 - val_accuracy: 0.6510\n",
            "Epoch 73/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7119 - accuracy: 0.7644 - val_loss: 1.3216 - val_accuracy: 0.6103\n",
            "Epoch 74/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7133 - accuracy: 0.7669 - val_loss: 1.4833 - val_accuracy: 0.5760\n",
            "Epoch 75/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7197 - accuracy: 0.7631 - val_loss: 1.2849 - val_accuracy: 0.6300\n",
            "Epoch 76/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7070 - accuracy: 0.7654 - val_loss: 1.3028 - val_accuracy: 0.6206\n",
            "Epoch 77/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7006 - accuracy: 0.7674 - val_loss: 1.2063 - val_accuracy: 0.6434\n",
            "Epoch 78/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.7007 - accuracy: 0.7714 - val_loss: 1.3585 - val_accuracy: 0.6065\n",
            "Epoch 79/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6942 - accuracy: 0.7718 - val_loss: 1.2547 - val_accuracy: 0.6326\n",
            "Epoch 80/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6887 - accuracy: 0.7729 - val_loss: 1.3159 - val_accuracy: 0.6189\n",
            "Epoch 81/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6817 - accuracy: 0.7768 - val_loss: 1.3533 - val_accuracy: 0.5997\n",
            "Epoch 82/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6788 - accuracy: 0.7754 - val_loss: 1.3026 - val_accuracy: 0.6293\n",
            "Epoch 83/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6772 - accuracy: 0.7765 - val_loss: 1.3695 - val_accuracy: 0.6060\n",
            "Epoch 84/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6707 - accuracy: 0.7809 - val_loss: 1.2177 - val_accuracy: 0.6372\n",
            "Epoch 85/100\n",
            "470/470 [==============================] - 8s 16ms/step - loss: 0.6674 - accuracy: 0.7787 - val_loss: 1.3473 - val_accuracy: 0.6222\n",
            "Epoch 86/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6614 - accuracy: 0.7815 - val_loss: 1.2630 - val_accuracy: 0.6324\n",
            "Epoch 87/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6620 - accuracy: 0.7845 - val_loss: 1.3125 - val_accuracy: 0.6173\n",
            "Epoch 88/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6570 - accuracy: 0.7838 - val_loss: 1.3332 - val_accuracy: 0.6226\n",
            "Epoch 89/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6575 - accuracy: 0.7848 - val_loss: 1.4207 - val_accuracy: 0.6008\n",
            "Epoch 90/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6469 - accuracy: 0.7876 - val_loss: 1.2817 - val_accuracy: 0.6320\n",
            "Epoch 91/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6442 - accuracy: 0.7869 - val_loss: 1.4027 - val_accuracy: 0.6107\n",
            "Epoch 92/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6373 - accuracy: 0.7903 - val_loss: 1.2163 - val_accuracy: 0.6491\n",
            "Epoch 93/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6368 - accuracy: 0.7909 - val_loss: 1.3295 - val_accuracy: 0.6233\n",
            "Epoch 94/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6431 - accuracy: 0.7899 - val_loss: 1.3182 - val_accuracy: 0.6264\n",
            "Epoch 95/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6334 - accuracy: 0.7933 - val_loss: 1.3654 - val_accuracy: 0.6146\n",
            "Epoch 96/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6286 - accuracy: 0.7927 - val_loss: 1.2124 - val_accuracy: 0.6549\n",
            "Epoch 97/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6275 - accuracy: 0.7943 - val_loss: 1.2508 - val_accuracy: 0.6451\n",
            "Epoch 98/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6232 - accuracy: 0.7953 - val_loss: 1.4195 - val_accuracy: 0.6023\n",
            "Epoch 99/100\n",
            "470/470 [==============================] - 7s 16ms/step - loss: 0.6168 - accuracy: 0.7967 - val_loss: 1.3516 - val_accuracy: 0.6172\n",
            "Epoch 100/100\n",
            "470/470 [==============================] - 7s 15ms/step - loss: 0.6182 - accuracy: 0.7970 - val_loss: 1.3284 - val_accuracy: 0.6245\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd345e54050>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled_2d, y_test, batch_size=500, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHQ328zYgDzY",
        "outputId": "485f0081-8323-4557-d35d-82268588f3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 11ms/step - loss: 1.1832 - accuracy: 0.6602\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1832314729690552, 0.6601864099502563]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XeH74INtf0Jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gpsgM1YPyyzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provas de conceito"
      ],
      "metadata": {
        "id": "6TqZzChny0Nd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzOGjyL4Es9e"
      },
      "source": [
        "Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpzS03K1EvEV"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(92, return_sequences=True),input_shape=(1,92)))\n",
        "\n",
        "\n",
        "model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#model.add(Bidirectional(LSTM(92,return_sequences=True,dropout=0.5, recurrent_dropout=0.5,activation='tanh')))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Bidirectional(LSTM(92,return_sequences=True,activation='tanh')))\n",
        "#model.add(Bidirectional(LSTM(92,return_sequences=True,dropout=0.5, recurrent_dropout=0.5,activation='tanh')))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Bidirectional(LSTM(92,return_sequences=True,activation='tanh')))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Bidirectional(LSTM(92,activation='tanh')))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))\n",
        "#model.add(Dense(64, activation='relu', input_shape=(784,)))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "#model.add(Dense(64, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "#model.add(Dense(64, activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(Dropout(0.2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CCWckR4FSCT"
      },
      "source": [
        "Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTqbpF-qFT9K"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq2JS6VUFY3s"
      },
      "source": [
        "Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqhdamQWFbmj"
      },
      "source": [
        "model.fit(X_train_scaled, y_train, batch_size=100, epochs=20, verbose=1, validation_data=(X_valid_scaled, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing a simpler model"
      ],
      "metadata": {
        "id": "zhBKHwrpcRdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = Sequential()\n",
        "\n",
        "#model.add(Bidirectional(LSTM(92, return_sequences=True),input_shape=(1,92)))\n",
        "\n",
        "#model.add(Dense(18, activation='softmax'))\n",
        "\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "BFGksL1AcDgV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}